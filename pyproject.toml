[project]
name = "agent-spike"
version = "0.1.0"
description = "AI agent spike for exploration"
requires-python = ">=3.14"
authors = [
    {name = "Agent Spike"}
]
license = {text = "MIT"}
keywords = ["agent", "spike"]
classifiers = [
    "Development Status :: 3 - Alpha",
    "Environment :: Console",
    "Intended Audience :: Developers",
    "License :: OSI Approved :: MIT License",
    "Natural Language :: English",
    "Operating System :: OS Independent",
    "Programming Language :: Python",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.14",
    "Topic :: Software Development",
]
dependencies = [
    "openai>=2.7.0",
    "python-dotenv>=1.2.1",
    "typer>=0.9",
    "fastapi>=0.109.0",
    "uvicorn[standard]>=0.27.0",
    "websockets>=12.0",
    "qdrant-client>=1.7.0",
    "tiktoken>=0.5.0",
    "httpx>=0.27.0",
    "neo4j>=6.0.3",
    "surrealdb>=1.0.0",
    "minio>=7.2.0",
    "bcrypt>=5.0.0",
    "pyjwt>=2.10.1",
    "opentelemetry-api>=1.38.0",
    "opentelemetry-sdk>=1.38.0",
    "opentelemetry-exporter-otlp-proto-grpc>=1.38.0",
    "opentelemetry-instrumentation-fastapi>=0.59b0",
    "opentelemetry-instrumentation-httpx>=0.59b0",
    "opentelemetry-instrumentation-logging>=0.59b0",
]

[project.optional-dependencies]
dev = [
    "pytest>=7.4",
    "pytest-asyncio>=0.23",
    "pytest-cov>=4.1",
    "pytest-mock>=3.12",
    # Include platform deps for testing compose/
    "pydantic-ai>=0.0.14",
    "pydantic-ai[ollama]>=0.1.0",
    "youtube-transcript-api>=1.2.3",
    "google-api-python-client>=2.0.0",
    "sentence-transformers>=2.2.0",
    "anthropic>=0.40.0",
    "rich>=14.2.0",
    "mcp>=1.20.0",
    "black>=23.0",
    "ruff>=0.1",
    "isort>=5.12",
    "mypy>=1.0",
]
notebook = [
    "jupyter>=1.0",
    "ipython>=8.0",
]
lesson-001 = [
    "pydantic-ai>=0.0.14",
    "pydantic-ai-slim[openai,anthropic]>=0.0.14",
    "python-dotenv>=1.0.0",
    "youtube-transcript-api>=0.6.2",
    "rich>=13.9.0",
]

[project.scripts]
agent-spike = "src.app.cli:app"

[tool.uv]
# Enable package mode so 'compose' is importable without PYTHONPATH hacks
package = true

[tool.setuptools.packages.find]
# Include compose/ and tools/ as top-level packages
include = ["compose*", "tools*"]

[tool.uv.workspace]
# Treat project root as single workspace with shared .venv
# All lessons share dependencies via dependency-groups below
# This prevents UV from creating per-lesson venvs
members = []

[tool.black]
line-length = 88
target-version = ["py314"]

[tool.ruff]
line-length = 88
target-version = "py314"
select = ["E", "F", "W", "I", "UP"]

[tool.isort]
profile = "black"
line_length = 88

[tool.mypy]
python_version = "3.14"
strict = true

[tool.pytest.ini_options]
testpaths = ["compose/tests"]
python_files = ["test_*.py"]
python_classes = ["Test*"]
python_functions = ["test_*"]
asyncio_mode = "auto"
asyncio_default_fixture_loop_scope = "function"
markers = [
    "unit: marks tests as unit tests (fast, no external deps)",
    "integration: marks tests as integration tests (requires external services)",
]
filterwarnings = [
    "ignore::DeprecationWarning:pydantic.*:",
]
addopts = "-v --tb=short"

[tool.coverage.run]
source = ["compose"]
omit = [
    "compose/tests/*",
    "compose/__pycache__/*",
    "*/__pycache__/*",
]
branch = true

[tool.coverage.report]
exclude_lines = [
    "pragma: no cover",
    "def __repr__",
    "raise NotImplementedError",
    "if TYPE_CHECKING:",
    "if __name__ == .__main__.:",
]
show_missing = true
fail_under = 0

[dependency-groups]
lesson-001 = [
    "pydantic-ai>=1.9.1",
    "python-dotenv>=1.2.1",
    "rich>=14.2.0",
    "youtube-transcript-api>=1.2.3",
    "typer>=0.9",
]
lesson-002 = [
    "typer>=0.9",
]
lesson-003 = [
    # Coordinator depends on both lesson-001 and lesson-002
    {include-group = "lesson-001"},
    {include-group = "lesson-002"},
    "typer>=0.9",
]
lesson-004 = [
    # Observability depends on all previous lessons
    {include-group = "lesson-003"},
    "logfire>=2.0.0",
]
lesson-005 = [
    # Security guardrails (uses only stdlib, no external dependencies)
    {include-group = "lesson-004"},
]
lesson-006 = [
    # Memory with Mem0 (requires OpenAI for embeddings)
    {include-group = "lesson-005"},
    "mem0ai>=0.1.13",
]
lesson-007 = [
    # Cache Manager with Qdrant (vector DB for semantic search)
    {include-group = "lesson-003"},  # Needs router, youtube, and webpage tools
    "qdrant-client>=1.7.0",
    "sentence-transformers>=2.2.0",
    "tqdm>=4.66.0",
    "google-api-python-client>=2.0.0",  # For fetch_channel_videos.py
]
lesson-008 = [
    # Batch Processing with OpenAI (50% cost savings)
    {include-group = "lesson-007"},  # Needs cache manager
    "openai>=1.54.0",
]
lesson-009 = [
    # Minimal Orchestrator (tests orchestration pattern)
    {include-group = "lesson-003"},  # Needs youtube + webpage sub-agents
    "openai>=1.54.0",  # For gpt-5-nano
]
lesson-010 = [
    # Semantic Tag Normalization (taxonomy clustering)
    {include-group = "lesson-001"},  # Base dependencies (typer, rich)
    {include-group = "lesson-007"},  # Archive/cache services
]
api = [
    # FastAPI service for N8N integration (DEPRECATED - use platform instead)
    {include-group = "lesson-001"},  # YouTube agent
    {include-group = "lesson-007"},  # Cache manager
    "fastapi>=0.109.0",
    "uvicorn[standard]>=0.27.0",
]
platform-api = [
    # Lightweight API service (NO embeddings - use embeddings service for that)
    "fastapi>=0.109.0",
    "uvicorn[standard]>=0.27.0",
    "pydantic>=2.0.0",
    "qdrant-client>=1.7.0", # For cache storage (no embeddings in API)
    "httpx>=0.27.0", # For HTTP clients (docling-serve, etc.)
    "youtube-transcript-api>=1.2.3",
    "google-api-python-client>=2.0.0",
    "openai>=1.54.0",
    "anthropic>=0.40.0", # Needed by url_filter
    "pydantic-ai[ollama]>=0.1.0", # For tagging with Ollama (free local inference)
    "rich>=14.2.0",
    "typer>=0.9",
    "mcp>=1.20.0",
    "python-multipart>=0.0.20",
    "surrealdb>=1.0.0",
    "minio>=7.2.0",
]
platform-embeddings = [
    # Heavy ML service for embeddings (PyTorch + CUDA)
    {include-group = "platform-api"},
    "sentence-transformers>=2.2.0",  # Pulls in PyTorch/CUDA (~3GB)
]
platform = [
    # Full platform (all services)
    {include-group = "platform-embeddings"},
]
dev = [
    "pytest>=8.4.2",
    "pytest-asyncio>=1.3.0",
    "pytest-cov>=7.0.0",
    "pytest-mock>=3.15.1",
]
