[project]
name = "agent-spike"
version = "0.1.0"
description = "AI agent spike for exploration"
requires-python = ">=3.14"
authors = [
    {name = "Agent Spike"}
]
license = {text = "MIT"}
keywords = ["agent", "spike"]
classifiers = [
    "Development Status :: 3 - Alpha",
    "Environment :: Console",
    "Intended Audience :: Developers",
    "License :: OSI Approved :: MIT License",
    "Natural Language :: English",
    "Operating System :: OS Independent",
    "Programming Language :: Python",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.14",
    "Topic :: Software Development",
]
dependencies = [
    "openai>=2.7.0",
    "python-dotenv>=1.2.1",
    "typer>=0.9",
    "fastapi>=0.109.0",
    "uvicorn[standard]>=0.27.0",
    "websockets>=12.0",
    "qdrant-client>=1.7.0",
    "tiktoken>=0.5.0",
    "httpx>=0.27.0",
]

[project.optional-dependencies]
dev = [
    "pytest>=7.4",
    "black>=23.0",
    "ruff>=0.1",
    "isort>=5.12",
    "mypy>=1.0",
]
notebook = [
    "jupyter>=1.0",
    "ipython>=8.0",
]
lesson-001 = [
    "pydantic-ai>=0.0.14",
    "pydantic-ai-slim[openai,anthropic]>=0.0.14",
    "python-dotenv>=1.0.0",
    "youtube-transcript-api>=0.6.2",
    "rich>=13.9.0",
]

[project.scripts]
agent-spike = "src.app.cli:app"

[tool.uv]
package = false  # This is a learning project, not a library to publish

[tool.uv.workspace]
# Treat project root as single workspace with shared .venv
# All lessons share dependencies via dependency-groups below
# This prevents UV from creating per-lesson venvs
members = []

[tool.black]
line-length = 88
target-version = ["py314"]

[tool.ruff]
line-length = 88
target-version = "py314"
select = ["E", "F", "W", "I", "UP"]

[tool.isort]
profile = "black"
line_length = 88

[tool.mypy]
python_version = "3.14"
strict = true

[tool.pytest.ini_options]
testpaths = ["lessons/lesson-003"]
python_files = ["test_router.py"]
python_classes = ["Test*"]
python_functions = ["test_*"]

[dependency-groups]
lesson-001 = [
    "pydantic-ai>=1.9.1",
    "python-dotenv>=1.2.1",
    "rich>=14.2.0",
    "youtube-transcript-api>=1.2.3",
    "typer>=0.9",
]
lesson-002 = [
    "typer>=0.9",
]
lesson-003 = [
    # Coordinator depends on both lesson-001 and lesson-002
    {include-group = "lesson-001"},
    {include-group = "lesson-002"},
    "typer>=0.9",
]
lesson-004 = [
    # Observability depends on all previous lessons
    {include-group = "lesson-003"},
    "logfire>=2.0.0",
]
lesson-005 = [
    # Security guardrails (uses only stdlib, no external dependencies)
    {include-group = "lesson-004"},
]
lesson-006 = [
    # Memory with Mem0 (requires OpenAI for embeddings)
    {include-group = "lesson-005"},
    "mem0ai>=0.1.13",
]
lesson-007 = [
    # Cache Manager with Qdrant (vector DB for semantic search)
    {include-group = "lesson-003"},  # Needs router, youtube, and webpage tools
    "qdrant-client>=1.7.0",
    "sentence-transformers>=2.2.0",
    "tqdm>=4.66.0",
    "google-api-python-client>=2.0.0",  # For fetch_channel_videos.py
]
lesson-008 = [
    # Batch Processing with OpenAI (50% cost savings)
    {include-group = "lesson-007"},  # Needs cache manager
    "openai>=1.54.0",
]
lesson-009 = [
    # Minimal Orchestrator (tests orchestration pattern)
    {include-group = "lesson-003"},  # Needs youtube + webpage sub-agents
    "openai>=1.54.0",  # For gpt-5-nano
]
api = [
    # FastAPI service for N8N integration (DEPRECATED - use platform instead)
    {include-group = "lesson-001"},  # YouTube agent
    {include-group = "lesson-007"},  # Cache manager
    "fastapi>=0.109.0",
    "uvicorn[standard]>=0.27.0",
]
platform-api = [
    # Lightweight API service (NO embeddings - use embeddings service for that)
    "fastapi>=0.109.0",
    "uvicorn[standard]>=0.27.0",
    "pydantic>=2.0.0",
    "qdrant-client>=1.7.0",  # For cache storage (no embeddings in API)
    "httpx>=0.27.0",  # For HTTP clients (docling-serve, etc.)
    "youtube-transcript-api>=1.2.3",
    "google-api-python-client>=2.0.0",
    "openai>=1.54.0",
    "anthropic>=0.40.0",  # Needed by url_filter
    "rich>=14.2.0",
    "typer>=0.9",
]
platform-embeddings = [
    # Heavy ML service for embeddings (PyTorch + CUDA)
    {include-group = "platform-api"},
    "sentence-transformers>=2.2.0",  # Pulls in PyTorch/CUDA (~3GB)
]
platform = [
    # Full platform (all services)
    {include-group = "platform-embeddings"},
]
