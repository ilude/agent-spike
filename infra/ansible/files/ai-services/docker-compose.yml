services:
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    restart: unless-stopped
    ports:
      - "11434:11434"
    volumes:
      - ./data/ollama:/root/.ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    environment:
      - OLLAMA_HOST=0.0.0.0

  infinity:
    image: michaelf34/infinity:latest
    container_name: infinity
    restart: unless-stopped
    command: v2 --model-id Alibaba-NLP/gte-large-en-v1.5 --port 7997 --batch-size 16 --engine torch
    ports:
      - "7997:7997"
    volumes:
      - ./data/infinity:/app/.cache
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  docling:
    image: ghcr.io/docling-project/docling-serve:latest
    container_name: docling
    restart: unless-stopped
    ports:
      - "5001:5001"
    environment:
      - DOCLING_SERVE_ENABLE_UI=1
      - DOCLING_NUM_THREADS=8
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  n8n:
    image: n8nio/n8n:latest
    container_name: n8n
    restart: unless-stopped
    ports:
      - "5678:5678"
    volumes:
      - ./data/n8n:/home/node/.n8n
    environment:
      - N8N_BASIC_AUTH_ACTIVE=true
      - N8N_BASIC_AUTH_USER=admin
      - N8N_BASIC_AUTH_PASSWORD=admin
      - N8N_HOST=0.0.0.0
      - N8N_LISTEN_ADDRESS=0.0.0.0
      - N8N_PORT=5678
      - N8N_PROTOCOL=http
      - NODE_ENV=production

  surrealdb:
    image: surrealdb/surrealdb:latest
    container_name: surrealdb
    restart: unless-stopped
    ports:
      - "8080:8000"  # External 8080 to avoid conflict with whisper on 8000
    volumes:
      - ./data/surrealdb:/data
    command: start --user root --pass ${SURREALDB_PASSWORD} file:/data/database.db
    environment:
      - SURREAL_CAPS_ALLOW_ALL=true

  minio:
    image: quay.io/minio/minio:latest
    container_name: minio
    restart: unless-stopped
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - ./data/minio:/data
    environment:
      - MINIO_ROOT_USER=${MINIO_ACCESS_KEY}
      - MINIO_ROOT_PASSWORD=${MINIO_SECRET_KEY}
    command: server /data --console-address ":9001"

  # neo4j:
  #   image: neo4j:5-community
  #   container_name: neo4j
  #   restart: unless-stopped
  #   ports:
  #     - "7474:7474"
  #     - "7687:7687"
  #   volumes:
  #     - ./data/neo4j:/data
  #   environment:
  #     - NEO4J_AUTH=${NEO4J_AUTH}

  whisper:
    image: fedirz/faster-whisper-server:latest-cuda
    container_name: whisper
    restart: unless-stopped
    ports:
      - "8000:8000"
    volumes:
      - ./data/whisper:/root/.cache/huggingface
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    environment:
      - WHISPER__MODEL=Systran/faster-whisper-large-v3-turbo
    healthcheck:
      test: ["CMD", "python3", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8000/health')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s

# All data stored in ./data/ bind mounts for durability
# Run migrate-volumes.sh to copy existing named volume data before first deploy
