services:
  api:
    build:
      context: ..  # Root of project (to access tools/)
      dockerfile: compose/api/Dockerfile
    container_name: agent-spike-api
    ports:
      - "8000:8000"
    volumes:
      - ./data:/app/src/compose/data  # Mount data for access
      - ./api:/app/src/compose/api  # Hot reload for API code
      - ./services:/app/src/compose/services  # Hot reload for services
      - ../tools:/app/src/tools  # Mount tools for imports
      - /app/.venv  # Don't mount .venv (let Docker manage it)
    environment:
      - PYTHONUNBUFFERED=1
      - PYTHONPATH=/app/src  # Points to src/ to avoid shadowing stdlib
    env_file:
      - ../.env  # Load API keys from root .env
    command: uv run uvicorn compose.api.main:app --reload --host 0.0.0.0 --port 8000
    restart: unless-stopped
    networks:
      - agent-network

  docling:
    image: ghcr.io/docling-project/docling-serve-cpu:latest
    container_name: docling-serve
    ports:
      - "5001:5001"
    environment:
      - DOCLING_SERVE_ENABLE_UI=1
      - DOCLING_NUM_THREADS=4
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped
    networks:
      - agent-network

  qdrant:
    image: qdrant/qdrant:latest
    container_name: qdrant
    ports:
      - "6335:6333"  # HTTP API + Web UI (mapped to avoid conflicts)
      - "6336:6334"  # gRPC (mapped to avoid conflicts)
    volumes:
      - ./data/qdrant_storage:/qdrant/storage
    environment:
      - QDRANT__SERVICE__GRPC_PORT=6334
    restart: unless-stopped
    networks:
      - agent-network

  infinity:
    image: michaelf34/infinity:latest
    container_name: infinity
    command: v2 --model-id BAAI/bge-m3 --port 7997 --batch-size 32 --engine torch
    ports:
      - "7997:7997"
    volumes:
      - infinity_models:/app/.cache  # Persistent model storage for portability
    restart: unless-stopped
    networks:
      - agent-network

  n8n:
    image: n8nio/n8n:latest
    container_name: n8n
    ports:
      - "5678:5678"
    environment:
      - N8N_BASIC_AUTH_ACTIVE=true
      - N8N_BASIC_AUTH_USER=admin
      - N8N_BASIC_AUTH_PASSWORD=admin
      - N8N_HOST=0.0.0.0
      - N8N_PORT=5678
      - N8N_PROTOCOL=http
      - NODE_ENV=production
      - DB_SQLITE_POOL_SIZE=3
      - N8N_RUNNERS_ENABLED=true
      - N8N_BLOCK_ENV_ACCESS_IN_NODE=false
      - N8N_GIT_NODE_DISABLE_BARE_REPOS=true
      - N8N_ENFORCE_SETTINGS_FILE_PERMISSIONS=true
    env_file:
      - ../.env  # Loads N8N_ENCRYPTION_KEY and N8N_LICENSE_ACTIVATION_KEY from .env
    volumes:
      - ./data/n8n:/home/node/.n8n
      - ./data/n8n/workflows:/workflows
    entrypoint:
      - /bin/sh
      - -c
      - |
        echo "Checking for workflows to import..."
        if [ -d "/workflows" ] && ls /workflows/*.json >/dev/null 2>&1; then
          echo "Found workflows, importing from directory..."
          n8n import:workflow --input="/workflows" --separate 2>/dev/null || echo "Import completed or workflows already exist"
          echo "Workflow import complete"
        else
          echo "No workflows found in /workflows"
        fi
        echo "Starting n8n..."
        exec n8n start
    restart: unless-stopped
    networks:
      - agent-network

networks:
  agent-network:
    driver: bridge

volumes:
  infinity_models:  # Named volume for embedding model storage (portable across dev machines)
    driver: local
