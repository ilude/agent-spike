{
  "video_id": "8_7Sq6Vu0S4",
  "url": "https://www.youtube.com/watch?v=8_7Sq6Vu0S4",
  "fetched_at": "2025-11-15T18:18:20.487636",
  "source": "youtube-transcript-api",
  "import_metadata": {
    "source_type": "single_import",
    "imported_at": "2025-11-15T18:18:20.486586",
    "import_method": "cli",
    "channel_context": {
      "channel_id": null,
      "channel_name": null,
      "is_bulk_import": false
    },
    "recommendation_weight": 1.0
  },
  "raw_transcript": "Hello and welcome back to another episode of Tash Teaches. I'm Tash and in today's video I want to talk about something that has massively increased the effectiveness of my Claude code usage that we could call metarrompting. A lot of people who have come to Claude code have arrived here from using more kind of ignorant I would say childlike approaches to AI assisted coding with platforms like Vzero or Lovable and the whole vibe coding concept while lovely in theory of just saying do this do that make it this works to some extent but you'll notice that a lot of the time the things that you want don't actually get implemented properly or they break or they can't be effectively tested and you end up having to give 20 30 individual prompts to try and solve the singular problem or add the singular feature that you wanted to in the first place. So in order to explain this I want to bring your uh focus to this particular prompt that I tend to run anytime that I want to do anything of some substance. If I'm just trying to change the background of something from yellow to red, sure, I could do that myself. Go in and adjust the CSS of whatever it is that I'm building. Or I could just say make the background yellow, and that would work fine. But most of the time, I'm doing more complex things than that. Things that require multiple stages of changes across multiple files and analysis of certain things, and then ideally verification and testing to prove that what I did was right. So, I have this prompt that I call create prompt. The reason why we're talking meta prompting here is very rarely do I tell Claude what I want it to do and get it to go do it because most of the time there's assumptions that it will have or misalignments with my goals that mean that by me just saying what I want, it's not the clearest way for Claude to understand the instructions that I'm giving it. So, I've folded this up here because it's a pretty long prompt that I run. But this create prompt is a prompt engineer. We're going to go through this section by section and then I'm going to show you in practice how this might be useful. So, what I would usually do, let me just whip this up so I could show you is let's say I open up a new instance of Claude. Say I want to do a thing. Instead of saying I want to create a dashboard blah blah blah blah blah, what I would first do is do create prompt and then I tend to use my uh transcription tool. So I would say I want to create a dashboard utilizing blah blah blah blah blah blah blah blah. For some reason my uh transcription tool isn't working. But the point is it's going to then run this prompt. You are an expert prompt engineer for Claude Code specializing in crafting optimal prompts using XML tag structuring and best practices. Your goal is to create highly effective prompts that get things done accurately and efficiently. So the first stage is the user request. The user wants you to create a prompt for arguments. And this is whatever comes after this. If I do create prompt and I say blah blah blah blah blah blah, this right here is going to be passed through as an argument to this custom slash command. So the first thing it reads is it knows what it is. It knows what I want to do. Then we have this core process here. So I've broken this down that first it uses thinking in these thinking tags here to analyze what my request is. So clarity check first and foremost is it works out whether or not what I'm asking is clear enough. A lot of the time it is because usually I'll just put my transcript on and I'll say exactly what it is that I want to do. I'll really wax poetic there. But if there is not enough context, what it's going to do is let's scroll down a little bit here is it's going to ask for clarification. We'll skip back up again in a sec. But what happens in that first step is if it feels that there's not enough details, it's going to go ahead and ask me some questions. So, it's going to ask specific questions about the ambiguous aspects of my prompt. Blah blah blah blah blah. As I said, most of the time I'm giving it enough detail up front that it doesn't need to do that. But if I just said build a dashboard, it's going to want more information. So let's scroll back up here again for a sec because you can see that this whole thinking tag thing, it works out is this a single file clear goal or is it complex with multi files? Also, should this be broken down into one or multiple prompts? And if they are multiple prompts, could it be parallelized? is the tasks that I'm asking for, could they be run side by side if they're referencing different parts of the codebase and actually wouldn't be editing separate things or relying on previous steps to have been completed. So, it's going to work out is it one prompt, is it multiple, and if it's multiple, should they be done sequentially or in parallel? Then, it's going to figure that out. Then, it's going to look for how much reasoning it needs. Does it need to really think through any stages before doing that? Does it need to examine the codebase structure, the dependencies or existing patterns? Should it be a concise prompt or comprehensive on the task? What file references, bash commands, or MCP servers might be needed? And then verification. Does this task warrant built-in error checking or validation steps? Then it's going to figure that out and move on to the next stage, which as I said, interaction flow here is if it has clarification, it doesn't need that. It then goes on to confirm that it has figured out what it wants and it's going to say this is a complex prompt. Would you like me to continue? I could then give it a little bit more context if I need to. Most of the time I just say yes. And what it's going to do is it's going to then generate that prompt and save it to a folder that if doesn't already exist in the directory I'm in. It creates called prompts. And then it creates the name and the number. Multiple prompts. It does the same thing, but it does 001 blah blah blah 002 yada yada yada. How does it actually create this prompt then? So, let's close this up. The prompt construction rules. Um, Anthropic themselves recommend when using clawed code to structure your prompts with XML tags, which are effectively anytime you've seen something like this uh where it's inside of this this little bracket, you could add in your objective. And then having this closing bracket means that Claude can then pass that logic in a way that makes much more sense to it because it's breaking up this task into sections. So what is the objective? What is the context that's needed? What are the requirements, the constraints? And finally, what would the output be? So it's going to figure out all of these things and it's going to also put at the bottom very importantly success criteria. So if we were to have achieved the object of the objective using said context and fitting into these requirements and constraints with an output like this, how would we define the success and also how would we verify that we had achieved this? So this is very important. Also conditionally include these are all based off of anthropics documentation. Uh but we'll just skip through these. Sometimes if something does need extended reasoning, it's going to add in words like thoroughly analyze or deeply consider. And this is going to trigger extended thinking. Most of the time for me that triggers the sequential thinking MCP. Also, go beyond basics language. When I'm saying to create like a a UI for something or a dashboard, a lot of the time Claude will do the bare minimum and it won't look great unless for fun for for fun some funny reason. If you tell it to like impress you, go wild, you know, go beyond basics, it will actually stretch and do a little bit more. Particularly with the ability of Sonnet 4.5 to do some really pretty longunning tasks without any interference. Also, why is it necessary to tell us why something must be done? Also, will it need to call tools in parallel? Uh, we've got a bunch more stuff here, yada yada yada. I'm going to be uploading the this prompt um to uh GitHub so that you can use this yourself, but it's going to add in some of these conditional in inclusions that might or might not be helpful. Also, then output format. Same thing down here. It's going to follow the same approach every single time, adding one to the number. So great, these are the prompt construction rules. Then prompt patterns. So I've got a few in here. If it's a coding task, here's a little example. Claudes do recommend or anthropics documentations do recommend examples. So if you give something an example of how you would like the output to be, it's more likely to do a good job doing it. So here we go. If it's a coding task, it's usually going to have the objective, the context, the requirements, implementation, output, verification, and success criteria. Maybe if it's an analysis task, it's going to look at these kind of things. So the objectives, what files would need to be references, what are the requirements for set analysis? Output and again validation to make sure that that analysis is complete. Research, same kind of thing. What is the scope of the research? What do we need as deliverables for the research? Evaluation criteria on working out the quality of the research. Let's close this up. Uh where are we? No prompt patterns. There we go. Then the intelligence rules. So here are some important things as well. is that clarity first. If anything is unclear, you must ask the user before pro proceeding. A few clarifying questions save time. Would a colleague with minimal context understand this prompt? Context is critical. You always include why the task matters, who it's for, and what it will be used for in generated prompts. Again, this is super key for telling Claude why it's doing it, who it's for, and what it will be. Therefore, it's not just giving it a task, but it's giving it context around why this task must be completed. Also be explicit. Again, we need to be super clear about exactly what format is needed for this. What files must be created and what must they look like? Scope assessment. Again, simple tasks don't need massive prompts. Complex tasks are going to need really long prompts. Context loading only requests file reading as an actual tool call if the task explicitly requires understanding existing code or documentation. So again, it's going to put things in there. Precision versus brevity. Default to precision. It's okay to write a long and clear prompt. It beats a short and ambiguous one. Also, tool integrations. If there are any MCP servers that I have and it has access to, or bash commands, file references, it needs to mention which ones to use. Output clarity. Again, every prompt must specify exactly where to save its outputs using relative paths. Every prompt should include clear success criteria and verification steps. This is so so helpful. Sometimes, you know, we we ask it to do a thing, but there's no way that in in the way that it actually implements our decision without using meta prompting that it thinks through, okay, after I've done this, how can I verify that it's worked? And then also after saving the prompt, present this decision tree to the user. It says, um, if you've created one prompt, I've saved it here. Would you like to one, run the prompt now, two, review and edit it, three, save it for later, blah blah blah blah blah. If I choose option one, it invokes the next slash command, which is run prompt up here, which we'll have a look at in a sec. Um, if it's parallel, it will say, would you like me to run them in parallel, and it's going to launch three sub aents working on this with their own context window um simultaneously. And similarly, if it's sequential, it will do them one after the other. So, let's just fold this up one more time. Where are we? Intelligence rules. Okay, meta instructions. Again, first check if clarification is needed before generating the prompt. Also, it then goes and reads the prompt folder to make sure that um either it exists, if it doesn't exist, and if it does, what the number should be. It keeps prompt file names descriptive but concise. Adapt the XML structure to fit the task. Not every tag is needed every time. Consider the user's working directory as the root for all relative paths. Each prompt should contain only the prompt content, no preamble or explanation. And after saving, present the appropriate decision tree blah blah blah blah blah. Let's just close this up. We got one final thing down here of examples when to ask for clarification. If I said build a dashboard, you should ask the user what kind of dashboard, admin, analytics, userfacing, what data should it display, fix the bug, can you describe the bug? These are very simple things, but you know, you want for the prompt to push back if it doesn't feel it has the clarity. Okay, so this is the essence of meta prompting is the goal is not to tell Claude what you want it to do. The goal is to tell Claude what you would want it to do and therefore how would it like best to be asked to achieve that instead of explaining what you want and getting it to do it. You want to get it to think about how it would best do the task and create a prompt for that. Now, what I love to do is not just run this prompt directly in line in this chat window. You know, once the prompt is created, if I were to just say run prompt and then I actually like tag the prompt, it's going to use up a hell of a lot of context in this chat window. Um, and also in the creation of that prompt, it's used up a lot of context in thinking about how to create the prompt, which means we've actually polluted the the entire chat with context that is not necessary while it's figuring out what to do. The prompt in and of itself is a self-contained solution to the problem, which is why I have this next prompt here called run prompt. Let's just fold this up. Um, where are we? Uh I suppose we can't easily fold this up in the same way but the goal of this prompt is to execute one or more prompts from the folder as delegated subtasks. This is that key thing. Um these are when they spawn sub aents. So these are self-contained fresh context sub aents. The user specifies which prompt to run via arguments or because this is in line it will just know what to do. But the point is here if it's an single prompt it runs it on in and of itself. If it's multiple prompts blah blah blah blah blah. You can see here um a little bit more context, not super interesting to read through, but it's basically just explaining to Claude exactly how to launch these prompts as subtasks. So, let's actually have a look to see here how we would use this in practice. So, I'm going to run exactly the same prompt in two different windows, except in one of them, I'm going to create a prompt for the prompt and then run that. and in another I'm just gonna get Claude to do it in one shot with no more context. So, first I'm going to copy and paste this prompt and I'm going to run this in the this this little folder is called with metarrompting and then I'm going to create one which is without metaring. So, let's just go ahead and run that. And I'm going to put this over here for clarity. And then I'm going to create another window. And I'm going to go back and I'm going to go into the without meta prompting. And I'm going to just give it that exact direct prompt. So, we'll say I want to create a CLI based tool. We'll go enter. So, let's have a little look here. You can see that it's already asked for a bit more um a little bit more context. Whereas with here, it's probably There we go. It's just going I'll create a generative music CLI tool with trippy visuals. Straight away it started to create it. Whereas here it wants some context. So audio library preferences. Do you want to use a specific node.js audio library or open to recommendations? In this case I'm going to say I'm uh I'm open to the best uh library for this given the goal. In this case, I don't really know. Visual rendering. Should this use terminal graphics library like blessed? Yes, use blessed and make it beautiful and rainbow like and trippy. Number three, note sequencing. You mentioned 75% chance each 16th note plays. Should the pentatonic notes be picked randomly? Uh, let's do randomly. uh with a waiting towards uh roots, octaves and first and then fifths and then uh thirds etc. The goal should be that it sounds pleasing. Cool. Number four, runtime. Should this run indefinitely until stopped? Yes, indefinitely until controll C. And then five, are you okay with installing npm packages for this or do you want minimal dependencies? Yes, that's fine to install. So, I'm going to run with this. Let's go back over here. You can see that already Claude has created in this view a version of this. So, let's just give it a go. I'm going to do npm start and I'm going to open this up in another tab and let's just let's just see. Let's just see what happened. Obviously, it was a lot quicker without meta prompting, but let's see what the quality of the results are. Okay, so it did something, but it's a bit really. So, I'm going to close that out. Stopping the music. I hate how it uses these emojis, but it did something. So, I'm curious to see now the quality of the difference here. Let's just make these the same color so that we can see which one is which. I'm going to go back to the prompt here. So, should I proceed? Yes. Cool. So, Claude has gone ahead and created this prompt. Let's have a little look to see what it is. Let's just widen this for a second. So, the Here we go. The the objective. Build a terminalbased generative music application that creates pleasing blah blah blah blah blah. This is for personal creative exploration and ambient background music generated. Nice. Here's the context. This is a new node.js CLI application. Audio requirements. Here are all of the specific things that are needed. The visual requirements. It needs to use trippy colorful rainbow like aesthetics. Runtime requirements. Technical approach. So, it's going to analyze the best approach for this implementation. Considering the audio library selection, um, timing architecture, harmonic waiting, sample and hold logic, what to avoid? Avoid blocking operations, uniform random note selection. Avoid updating sample and hold every note. Avoid synchronous blocking, blah blah blah blah blah. It's already decided what the project should look like. Success criteria and then verification. Can you run the application? Let it play for 30 seconds. These kind of things probably do require my effort, but let's go ahead. So now all I have to do is just press one. And you're going to see that instead of now running it in this window, it's going to launch the run prompt prompt to then run said prompt. You can see it's gone and found it in this directory. I can show you that this folder itself only has in it prompts. Let's have a look in there. CD prompts. And inside of there is that folder. What's also nice is once the prompt has been run, it's going to relegate that prompt to a folder called completed. So, let's close this up and we're going to see what's happening. This task indicates that this is now running in its own self-contained sub agent workflow. Once it starts doing stuff, we can press control O uh wrong button control O and you'll be able to see exactly what's happening. So, right here, it's passed through that prompt. Let's get out of here. And we can see that very shortly it's going to start writing and reading and thinking about files. So let's just let that run and we'll come back to it in a second to see what it's done. Okay, I've just got back from my breakfast bagel and Claude seems to have completed the task. We can see here that it has created various files, the key implementation details, yada yada yada, and then the tools to run it. So I'm going to go ahead and do npm install. Let's just do this in a new tab. uh an npm install. Let's make this green as well. And then we want to do npm start. Very nice that we've got a high security vulnerability there. Let's give it a go. [Music] Kind of nice. I like that. And I think you'll agree that the overall adherence to my original prompt of having a bit more of like a a structured randomness [Music] compared to this this buggy clicky whatever's going on here. This is a damn a damn lot better. Nice. Okay. So just to verify one more time that how much more effective this is. I want to do a little uh adjustment to this. So now I want to do I want to add uh I'm going to do this with create prompt again as well. So create prompt. I want to add uh more of a rainbow fractal fractal trippy visual aspect to it as well as some sample and hold slightly affecting the sine waves uh feedback to create little timberal tambberal changes. And also I want to be able to uh select different scales in real time by pressing the right and left arrow keys. So I'm just going to run this in here. And then I'm also going to go back over here and I'm going to say I want to add exactly the same thing, but we're going to do it straight one shot and then with a prompt in between. So let's see how this runs. and uh we'll compare the results. Okay, so it actually wants a little bit more clarification. Rainbow fractal visuals. Do you want actual fractal patterns like mandelro? Um I'm thinking something between mandal brought and spirals and making it evolving uh and generative and directly related to the music. Okay. Number two, sine wave feedback. Should this be actual audio feedback delay or FM synthesis style? FM synthesis style modulation. Subtle warmth. Three. Scale selection. Should there be a visual indicator showing which selection? Um, we'll say yes. It should show in the bottom right. And we should do all of the modes of the major scale and also the two pentatonic scales and then four uh as I said above. And I think what's nice about this is it really helps you refine what it is that you want when you're asked more questions about it. And of course, instead of saying continue, I could have said after this, ask me some more questions as well. And that's so key to being able to just be sure that what it is that you're you're prompting for is um is going to be what you want because sometimes you actually have to ask yourself the questions, do I want this? Do I want that? How do I envision it? If if you don't know, then Claude definitely isn't going to know. So, let's run the updated version here in the oneshot prompt. Okay. So, you can see that it's creating some really kind of up problems here that weren't really fixed. This does look quite nice. I like that a lot. Let's actually see if we were to run this um if we were to run this in just regular terminal to see if that makes it any better. npm start. [Music] Okay, so we're still having all sorts of problems there. I do love those colors. Those are really very nice. Can I change scale? We're in pentatonic minor now. Major minor. Cool. So, it does work, but it's not quite what I want. So, let's go back to here, and we should in theory have our updated prompt. So, let's run it, and then let's see what we get. While that's running, let's actually have a look to see what the prompt was like that it created for this enhancement. So the objective enhancing the existing music CLI tool with these three main improvements context the existing application. This is important. It tells it about what we already have. Examine these files. It wants to be a more trippy fractal-based situation. Here's the visual enhancement requirements. So we need it to be more fractal with generative and continuously evolving visual style maintaining rainbow spectrum but they should be trippy and mesmerizing. Consider uni-ode box drawing performance blah blah blah blah blah audio enhancement requirements. So now we need to add in a little bit more complexity which is that feedback which to be honest I don't think we even really had in this view. Um maybe a little bit but very subtle. Um and then let's have a little look here. Interactive scale selection uh keyboards. You just see like how indepth this is and all I had to do was just answer a couple of questions. So technical approach research fractal generation suitable for terminal rendering. This is baked into the prompt before it does anything else. Scale system FM system. Very nice. What to avoid and why? Avoid complex fractal algorithms in the audio of Fred. Avoid harsh FM tambers. Um, yep, great. Avoid pixel perfect fractal rendering. Modify existing files, these ones. And here are the success criteria as well as then verification. Very nice. So, this looks as though it's about to finish. Um, I'd be curious to know exactly how long it took to do. Uh, but we'll come back to this in one moment. Okay. It took about 8 minutes to complete that prompt, but we are now uh done. Just before we dial that in, let's give it one more occasion of the cheap buggy crappy one, the oneshot prompt versus what it would be if we did those two prompts. So, here we go. I'm very excited. [Music] Let's change key. Bit weird what's happening up here with the text. And now we're in pentatonic minor. [Music] Let's do 3GM. [Music] Oh, Lydian. We got a bunch of nice scales in. Anyway, you get the idea. I think what's just really great about this approach is not just does it help you understand what you want before you ask for it, but it just makes the entire process of actually prompting so much easier because you don't have to think about the things that the LLM will need as a human being like okay well what does Claude need instead you ask Claude what do you need out of interest let's just check out the codebase here I've got the without metaring and with metaring here let's just have a look to see how it was even constructed so when I just asked for it without creating prompts beforehand it created just this I was going to say a monolith but it's not even really a very big file file. It's a 286 line single index.js and then it's got some node modules here. Um, that's it. Let's see how it organized things in the prompt based one. So, you can see here that we've got that index.js entry point. It's only 63 lines long and it references the source files here where we've got an independent script for audio. We've also then got an independent script for visuals here. Um, very nice. We've even got a little read me here that explains exactly how to use it, all that sorts of information. So, I know that this seems um potentially a little bit long- winded, you know, and as I said at the beginning of this video, if you just want to change the background color of something to red to yellow, or you want to change a font, there's no point you wasting the time uh getting Claude to think about how it should ask itself to do that thing. But when you want to compound the upgrades of what you want to make to your system, to your codebase, I highly recommend running this prompt beforehand because the quality, as you can see, is just so much better. I know that we looked at it today in the context of creating a CLI based tool, but this works for refactoring, this works for database migrations, this works for whatever it is that you want to do that requires a little bit more thought than just do X thing. Um, so highly recommend it. I'm going to put the link to be able to download this prompt in the description down below. Give it a go and let me know what you think. And uh also let me know if you're interested in any more videos about some of the prompts that I use. I've got a couple of really exciting ones that I think we could look at next. But in the meantime, uh that's all that's all folks and thank you for watching.",
  "timed_transcript": null,
  "youtube_metadata": {
    "video_id": "8_7Sq6Vu0S4",
    "title": "Stop Telling Claude Code What To Do",
    "description": "\ud83d\udcdd Prompts available on GitHub: https://github.com/glittercowboy/taches-cc-prompts.git\n\ud83d\ude4b\ud83c\udffc\u200d\u2642\ufe0f Join live Q&A calls with me once a week for just $47/m (7-day free trial): \nhttps://claude-coders.circle.so/checkout/claude-coders\n\nA walkthrough of how I use \"meta-prompting\" with Claude Code\u2014where instead of directly telling Claude what to do, I first ask it to create an optimal prompt for the task.\n\nI demonstrate a custom /create-prompt command that acts as a prompt engineer. It analyzes your request, asks clarifying questions if needed, structures the prompt with XML tags, and saves it to a prompts folder. Then a /run-prompt command executes these as fresh sub-agents with clean context windows.\n\nThe comparison shows building a generative music CLI tool with and without this approach. The meta-prompted version produces better code organization (modular vs monolithic), asks useful clarifying questions upfront, and includes built-in verification steps.\n\nWorth noting: In retrospect, the single-shot prompt would've been fairer if I'd given it the same clarifying context I provided to the meta-prompt version. But the core advantage still holds\u2014forcing Claude to think about how it should be asked to do something produces more thoughtful, structured results for complex tasks.\n\nThis is 100% overkill for simple changes but I've found it be essential for any substantial work I do like big refactoring tasks, database migrations, or multi-file features that require incredibly specific instructions.\n\n0:00 Intro\n00:56 The 'Create Prompt' Prompt\n13:36 The 'Run Prompt' Prompt\n14:23 Using Meta-Prompting in Practice\n29:09 Outro",
    "published_at": "2025-11-13T18:07:19Z",
    "channel_id": "UCQhvDZeUrxPq9p3SkbTngkA",
    "channel_title": "T\u00c2CHES TEACHES",
    "duration": "PT30M18S",
    "duration_seconds": 1818,
    "view_count": 4532,
    "like_count": 215,
    "comment_count": 68,
    "tags": [],
    "category_id": "24",
    "thumbnails": {
      "default": {
        "url": "https://i.ytimg.com/vi/8_7Sq6Vu0S4/default.jpg",
        "width": 120,
        "height": 90
      },
      "medium": {
        "url": "https://i.ytimg.com/vi/8_7Sq6Vu0S4/mqdefault.jpg",
        "width": 320,
        "height": 180
      },
      "high": {
        "url": "https://i.ytimg.com/vi/8_7Sq6Vu0S4/hqdefault.jpg",
        "width": 480,
        "height": 360
      },
      "standard": {
        "url": "https://i.ytimg.com/vi/8_7Sq6Vu0S4/sddefault.jpg",
        "width": 640,
        "height": 480
      },
      "maxres": {
        "url": "https://i.ytimg.com/vi/8_7Sq6Vu0S4/maxresdefault.jpg",
        "width": 1280,
        "height": 720
      }
    },
    "fetched_at": "2025-11-15T18:18:20.486546",
    "all_urls": [
      "https://github.com/glittercowboy/taches-cc-prompts.git",
      "https://claude-coders.circle.so/checkout/claude-coders"
    ],
    "blocked_urls": [
      "https://claude-coders.circle.so/checkout/claude-coders"
    ],
    "content_urls": [
      "https://github.com/glittercowboy/taches-cc-prompts.git"
    ],
    "marketing_urls": [],
    "url_filter_version": "v1_heuristic_llm",
    "url_filtered_at": "2025-11-15T19:52:13.722281"
  },
  "llm_outputs": [
    {
      "output_type": "metadata",
      "output_value": "{\n  \"title\": \"Tash Teaches: Metarprompting for Claude Code (Prompt Engineering Tutorial)\",\n  \"summary\": \"A tutorial/demo on metarprompting for Claude Code, showing how to craft self-contained prompts and meta-prompts to guide multi-file coding tasks, with a practical CLI music tool example that demonstrates improved quality and workflow over one-shot prompting.\",\n  \"subject_matter\": [\n    \"metarprompting\",\n    \"prompt_engineering\",\n    \"Claude Code\",\n    \"XML_tag_structuring\",\n    \"thinking_tags\",\n    \"sub-agent_workflows\",\n    \"CLI_tool_development\"\n  ],\n  \"entities\": {\n    \"named_things\": [\n      \"Claude Code\",\n      \"Vzero\",\n      \"Lovable\",\n      \"Anthropic\",\n      \"XML tags\",\n      \"GitHub\",\n      \"Blessed\",\n      \"Node.js\",\n      \"npm\"\n    ],\n    \"people\": [\n      \"Tash\"\n    ],\n    \"companies\": [\n      \"Anthropic\",\n      \"Tash Teaches\"\n    ]\n  },\n  \"techniques_or_concepts\": [\n    \"metar prompting / meta prompting\",\n    \"prompt engineering with XML-tag structuring\",\n    \"thinking tags and clarity checks\",\n    \"verification and success criteria\",\n    \"self-contained prompts / sub-agent workflows\",\n    \"parallel vs sequential execution of prompts\",\n    \"prompt patterns for coding tasks\"\n  ],\n  \"tools_or_materials\": [\n    \"Claude Code\",\n    \"Node.js\",\n    \"npm\",\n    \" Blessed (terminal graphics library)\",\n    \"GitHub (prompt storage)\"\n  ],\n  \"key_points\": [\n    \"Metarprompting can massively increase the effectiveness of Claude Code compared to Ignores/straight prompts.\",\n    \"Use a structured prompt with XML tags to separate objective, context, requirements, constraints, output, and success criteria.\",\n    \"Think in terms of thinking tags, clarity checks, and built-in verification to avoid misalignment and rework.\",\n    \"Prompts can create self-contained sub-agents, saving outputs to a prompts folder and optionally running prompts in parallel or sequentially.\",\n    \"An applied example builds a CLI-based generative music tool in Node.js, demonstrating improved quality over a direct one-shot prompt, and it took about 8 minutes to complete the enhanced prompt.\"\n  ],\n  \"content_style\": \"tutorial\",\n  \"difficulty\": \"intermediate\",\n  \"references\": [\n    {\n      \"type\": \"tool\",\n      \"name\": \"Claude Code\",\n      \"url\": null,\n      \"description\": \"AI coding assistant by Claude/Anthropic used in the video to demonstrate metaprompting and prompt engineering.\"\n    },\n    {\n      \"type\": \"tool\",\n      \"name\": \"Vzero\",\n      \"url\": null,\n      \"description\": \"AI coding assistant platform mentioned as a comparison in the video.\"\n    },\n    {\n      \"type\": \"tool\",\n      \"name\": \"Lovable\",\n      \"url\": null,\n      \"description\": \"AI coding platform mentioned as a baseline in the discussion.\"\n    },\n    {\n      \"type\": \"documentation\",\n      \"name\": \"Anthropic prompt engineering guidelines (XML-tag structure for Claude prompts)\",\n      \"url\": null,\n      \"description\": \"Anthropic guidance suggesting XML-tag structured prompts to improve Claude interactions.\"\n    },\n    {\n      \"type\": \"video\",\n      \"name\": \"Tash Teaches YouTube channel\",\n      \"url\": null,\n      \"description\": \"Channel hosting the discussed metaprompting tutorial by Tash.\"\n    },\n    {\n      \"type\": \"github_repo\",\n      \"name\": \"Meta-prompt prompts folder / prompt storage workflow\",\n      \"url\": null,\n      \"description\": \"Conceptual storage and execution workflow described for storing and running prompts.\"\n    },\n    {\n      \"type\": \"tool\",\n      \"name\": \"Blessed\",\n      \"url\": null,\n      \"description\": \"Terminal graphics library used for visual UI in the CLI tool example.\"\n    },\n    {\n      \"type\": \"tool\",\n      \"name\": \"Node.js\",\n      \"url\": null,\n      \"description\": \"JavaScript runtime used to build the CLI tool.\"\n    },\n    {\n      \"type\": \"tool\",\n      \"name\": \"npm\",\n      \"url\": null,\n      \"description\": \"Package manager used to install dependencies for the CLI tool.\"\n    }\n  ]\n}",
      "generated_at": "2025-11-15T18:19:02.421849",
      "model": "claude-3-5-haiku-20241022",
      "cost_usd": 0.001,
      "prompt_tokens": null,
      "completion_tokens": null
    }
  ],
  "derived_outputs": [],
  "processing_history": []
}