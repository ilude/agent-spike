{
  "video_id": "vjvZMK5C0pk",
  "url": "https://www.youtube.com/watch?v=vjvZMK5C0pk",
  "fetched_at": "2025-11-10T00:20:26.763059",
  "source": "youtube-transcript-api",
  "import_metadata": {
    "source_type": "bulk_channel",
    "imported_at": "2025-11-10T00:20:26.763059",
    "import_method": "cli",
    "channel_context": {
      "channel_id": null,
      "channel_name": null,
      "is_bulk_import": true
    },
    "recommendation_weight": 0.5
  },
  "raw_transcript": "why did deep seek work and what is everybody else doing now that deep seek is here this is going to be a bit of a longer one but now that deep seek is number one in the App Store I think it Bears unpacking the implications of what is going on so number one besides putting on a beanie is deep seek got to the App Store top spot with two innovations people aren't talking about one they showed their reasoning that is a big big deal it makes it easy for people to edit change adjust their prompts in fact I have heard that open AI is using those reasoning outputs that deep seek openly displays to help with model distillation already so like already the learnings from Deep seek are getting back to open AI but the larger the larger lesson learned there is that showing reasoning is a UI Innovation that more model makers should adopt it makes it really obvious what the model is doing that leads me to Innovation number two which is by offering it for free and by making R1 a reasoning model widely available in the App Store you are getting to what I call the autocomplete crowd I have lots of folks I know like this who are outside Tech many others do too I like to think of it as uncle's T at Thanksgiving who will tell you chat GPT is nothing but autocomplete and roll his eyes over the turkey it's a chat gp2 chat gpt2 level response it's like I saw this a few years ago it was kind of terrible and I don't think it's gotten better since well it's hard to argue that it's not gotten better when you're looking at Deep seek and you can literally see the reasoning and I think that is a big factor in why this app has shot to the top in the App Store I don't think there was any gaming involved I've seen people who said well they game the algorithm I don't think they did I think they just produced a really good experience so this brings me to the second part of the video what is everybody doing about that number one everybody is not reading their terms of service which are super creepy and concerning if you look at it you only get redressed through Chinese courts they do not actually delete your data when you delete your account they are keeping a monitoring table that they tell you that they are keeping for quote unquote illegal activities that they won't Define they do not clearly give you rights to the model outputs So in theory if you got a startup idea from a deep seek model output if is possible that deep seek could make a legal claim to that startup I don't know that they will I'm not saying that they will but the fact that the legal terms aren't clear should be really worrying and if you compare them versus open AI like people complain a lot and rightly hold open Ai and other model makers to a high bar deep seek is a lot farther back on that deep seek has really really concerning uh and invasive terms of use they log your keystrokes now my crowd the people people who are talking here are going to immediately say that doesn't matter I can run the model locally and my answer to you is you can run the model locally but 99.99% of people are using the freaking app and they are going through that same terms of service and not even noticing so that's the first thing that's happening and it is a concern if you're worried about Tik Tok and you're worried about like the app collection and data collection from Tik Tok I would argue this is worse because it captures your direct thinking and the model outputs are things you can't necessarily use it's scary okay the second implication around what people are doing is model makers in the US are desperately playing catchup that's not a surprise right but they're playing catchup in interesting ways they are doubling down on the fact that they need the money they need the billions of dollars they're Investing For chips for Next Generation models and they're arguing it on two points which I think are both correct first if you want to make a Next Generation model that is much harder than making a model for parody and what deep seek has done is make a model that seeks to be roughly on parody with state-of-the-art and that is easier versus making a model that is going to push The Cutting Edge and that's much more expensive and so that's that's Piece One Piece two is serving all of that inference serving all of that compute to people who ask for responses is not cheap and it takes a lot of chips and so what Wall Street didn't understand yesterday is that most of the chips that people buy are for inference it's for serving the model it is not for training the model most of Jensen sales are for serving the model the reason deep seek went down yesterday is because they did not have enough chips to serve the model at scale and so I I think that there's a little bit of a defensiveness there I've noticed that I'm not discounting it people do get defensive when competition comes up but I think net net they're probably correct that they need the money to advance the field now I will say one of the things that is under discussed and this is the third thing that like people aren't really talking about but people are actually doing uh so if you're in the Tech Community if you're a developer and you're like replicating what deep seek is doing what you are doing in replicating the model and the technical details of the paper is something that was not possible but was tried two years ago and so what they are able to do now with Group Policy reinforcement with essentially reading reasoning out of the data stream that they're training on was tried previously and it didn't work and now it does and the reason why it works is because reasoning models like 01 have come out generated a ton of tokens into the data stream we have a lot of evidence that's very public of humans either praising or criticizing specific model responses and that is now in the general internet data availability which means deep seek can train on it which means that other model makers can train on it too and so what we're seeing really is a reasoning takeoff moment before there weren't enough examples of model reasoning out there with humans either saying yes or no good or bad for models to learn what reasoning looked like just by reading through the data set and doing some group policy reinforcement now there are in the last year and a half two years that has changed now there's enough reasoning examples out there that you can hit a critical mass I think the number I saw for critical mass was 800,000 responses or 800,000 samples I don't know if that exact number is true but the point is there's enough of them out there that you critical mass and you were able to actually use a technique that had been tried previously and discarded to grow a reasoning model more organically for lack of a better term we're not talking about artisanal organic models here we're saying basically the model didn't need an external validation point to learn reasoning and that is a big deal and that is being rapidly replicated now that people have figured out it works and so that's the third thing people are doing is they're replicating deep seeks results and they're seeing it work and that means that we are at a point where models are effectively very close to self-improving they can look at reasoning they can learn reasoning on their own and if they can do that then the higher quality responses they produce into the data stream are going to be used by the next generation of models to improve faster so that is one of the big long-term implications is that effectively deep seek has accelerated model development Again by making reasoning more transparent and available so we'll see what happens it's a collection of things so first off we talked about deep seek and their position in the App Store and why it worked and second I covered the three things that I think are most important coming out of this right like how we handle the terms of service what the model makers are doing as far as their investment levels and finally what actual people are doing when they figure out that they can replicate this uh reasoning development Chain of Thought development from the data stream which I think is perhaps the most interesting implication so far so it's been weird it's been fun seek is here",
  "timed_transcript": null,
  "youtube_metadata": {
    "source": "youtube-transcript-api",
    "video_id": "vjvZMK5C0pk",
    "title": "Why DeepSeek beat ChatGPT in the App Store, plus Privacy, Data Center Investment, AI Acceleration",
    "description": "Wrote about this here: https://open.substack.com/pub/natesnewsletter/p/deepseeks-exponential-growth-and?r=1z4sm5&utm_campaign=post&utm_medium=web&showWelcomeOnShare=true\nMy site: https://natebjones.com/\nMy links: https://linktr.ee/natebjones\nMy substack: https://natesnewsletter.substack.com/\n\nTakeaways:\n 1. Reasoning Transparency as a Game-Changer: DeepSeek\u2019s innovation in showing reasoning outputs revolutionizes model transparency, making it easier for users to edit and adjust prompts while improving model understanding and usability.\n 2. Mass Adoption via Accessibility: By offering the reasoning model R1 for free, DeepSeek tapped into a broader, non-tech-savvy audience, leading to its rapid climb to the top of the App Store.\n 3. Concerning Terms of Service: DeepSeek\u2019s invasive terms of service raise privacy concerns, including data retention, keystroke logging, and unclear ownership of outputs.\n 4. Reasoning Models Enable Acceleration: Advances in reasoning models, driven by increased data availability and group policy reinforcement, allow self-improving systems, speeding up model development.\n 5. Critical Mass of Reasoning Data: The availability of over 800,000 reasoning examples has hit a threshold, enabling models like DeepSeek to refine reasoning capabilities effectively.\n 6. Inference Costs and Chip Shortages: DeepSeek\u2019s success highlights the immense cost and infrastructure challenges of serving AI models at scale, emphasizing the need for continued investment in AI infrastructure.\n 7. Replicability of Reasoning Techniques: Developers are rapidly replicating DeepSeek\u2019s reasoning breakthroughs, which could democratize these advancements and drive further innovation.\n\nQuotes:\n\u201cWe\u2019re at a reasoning takeoff moment\u2014models can now learn reasoning on their own, accelerating development like never before.\u201d\n\u201cDeepSeek\u2019s transparency makes it hard to argue that AI hasn\u2019t improved, even for the skeptics who still see it as \u2018autocomplete.\u2019\u201d\n\u201cIf you\u2019re worried about TikTok\u2019s data collection, DeepSeek might be worse\u2014it captures your direct thinking and keeps it.\u201d\n\nSummary:\nDeepSeek\u2019s rise to the top of the App Store stems from two major innovations: displaying reasoning outputs for better transparency and offering its R1 model for free. These features made AI accessible to a broader audience, even skeptics, while driving improvements in user experience. However, DeepSeek\u2019s invasive terms of service raise significant privacy concerns. On the technical front, advances in reasoning data and techniques have created a tipping point for self-improving models, enabling faster innovation. Despite DeepSeek\u2019s success, it faces challenges around infrastructure costs and scalability, which have sparked broader efforts among developers to replicate its reasoning breakthroughs.\n\nKeywords:\nDeepSeek, reasoning transparency, AI innovation, App Store, R1 model, terms of service, data privacy, group policy reinforcement, reasoning models, AI scalability, chip shortages, self-improving AI models, data retention, inference costs",
    "published_at": "2025-01-28T17:01:10Z",
    "channel_id": "UC0C-17n9iuUQPylguM1d-lQ",
    "channel_title": "AI News & Strategy Daily | Nate B Jones",
    "duration": "PT8M31S",
    "duration_seconds": 511,
    "view_count": 4999,
    "like_count": 404,
    "comment_count": 85,
    "tags": [],
    "category_id": "22",
    "thumbnails": {
      "default": {
        "url": "https://i.ytimg.com/vi/vjvZMK5C0pk/default.jpg",
        "width": 120,
        "height": 90
      },
      "medium": {
        "url": "https://i.ytimg.com/vi/vjvZMK5C0pk/mqdefault.jpg",
        "width": 320,
        "height": 180
      },
      "high": {
        "url": "https://i.ytimg.com/vi/vjvZMK5C0pk/hqdefault.jpg",
        "width": 480,
        "height": 360
      },
      "standard": {
        "url": "https://i.ytimg.com/vi/vjvZMK5C0pk/sddefault.jpg",
        "width": 640,
        "height": 480
      },
      "maxres": {
        "url": "https://i.ytimg.com/vi/vjvZMK5C0pk/maxresdefault.jpg",
        "width": 1280,
        "height": 720
      }
    },
    "fetched_at": "2025-11-15T19:27:31.661474",
    "all_urls": [
      "https://open.substack.com/pub/natesnewsletter/p/deepseeks-exponential-growth-and?r=1z4sm5&utm_campaign=post&utm_medium=web&showWelcomeOnShare=true",
      "https://natebjones.com/",
      "https://linktr.ee/natebjones",
      "https://natesnewsletter.substack.com/"
    ],
    "blocked_urls": [
      "https://linktr.ee/natebjones"
    ],
    "content_urls": [
      "https://open.substack.com/pub/natesnewsletter/p/deepseeks-exponential-growth-and?r=1z4sm5&utm_campaign=post&utm_medium=web&showWelcomeOnShare=true",
      "https://natesnewsletter.substack.com/"
    ],
    "marketing_urls": [
      "https://natebjones.com/"
    ],
    "url_filter_version": "v1_heuristic_llm",
    "url_filtered_at": "2025-11-15T19:52:26.261187"
  },
  "llm_outputs": [
    {
      "output_type": "tags",
      "output_value": "{\n  \"video_title\": \"Deep Seek tops the App Store: reasoning UI, data privacy concerns, and the future of AI model development\",\n  \"tags\": [\"large-language-models\", \"model-reasoning\", \"chain-of-thought\", \"ai-inference\", \"data-privacy\"],\n  \"summary\": \"Explores why Deep Seek became top in the App Store, the significance of its reasoning UI, concerns about terms of service and data privacy, and how competitors and the industry are responding.\"\n}",
      "generated_at": "2025-11-10T00:20:43.883502",
      "model": "claude-3-5-haiku-20241022",
      "cost_usd": 0.001,
      "prompt_tokens": null,
      "completion_tokens": null
    }
  ],
  "derived_outputs": [],
  "processing_history": []
}