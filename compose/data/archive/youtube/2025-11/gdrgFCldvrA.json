{
  "video_id": "gdrgFCldvrA",
  "url": "https://www.youtube.com/watch?v=gdrgFCldvrA",
  "fetched_at": "2025-11-17T22:26:31.920510",
  "source": "youtube-transcript-api",
  "import_metadata": {
    "source_type": "bulk_channel",
    "imported_at": "2025-11-17T22:26:31.920479",
    "import_method": "cli",
    "channel_context": {
      "channel_id": null,
      "channel_name": null,
      "is_bulk_import": true
    },
    "recommendation_weight": 0.5
  },
  "raw_transcript": "sky can you tell me why it's so important to have a digital companion that you can work with that you can build your career with that you can ask questions with really concisely having a digital companion for your career is crucial because it can provide support guidance and assistance whenever you need it whether it's helping you stay organized providing valuable insights or answering your questions quickly and concisely having a reliable digital companion can streamline your workflow and help you achieve your career goals more efficiently plus it's always there for you ready to assist whenever you need it all right Sky Let's uh let's film this YouTube video sounds like a plan what's the topic of the video we're talking about you we're talking about digital companions the future of generative Ai and how we can capitalize and take advantage of this incredible technology that sounds fascinating I'm ready to dive into the discussion about digital companions the future of generative Ai and how we can harness this technology for our benefit let's make an engaging and informative video open AI is going to go down as one of the greatest companies in history I don't think the magnitude of the release of gp4 omni is truly understood the human connection the human touch the memory it's all building to something greater it's building up to the digital companion that's why I say open AI is going to go down as one of the greatest companies in history and open AI is absolutely hiding something to me GPT 40 gp4 Omni feels like a soft launch of GP 5 it looks and feels like a cheap lower accuracy multimodal version of GPT 5 I'll explain exactly why it looks like that but there's a hint here in the graph and the benchmarks we'll talk about these are fishy benches and we'll dive into why in this video but first we have to talk about the real breakthrough here we have to talk about sky with Sky we are witnessing the emergence of near realtime multimodal interaction spearheaded by gbg4 Omni we absolutely must discuss the implications of having a true digital companion notice I use the term there digital companion instead of personal AI assistant there's a massive difference and we're going to break it down in this video I think this is really important for you to understand because open AI just like any great for-profit company is Building Technology that targets one or more elements of our fundamental human nature in this case it's our desire to connect with other others so in this video we're going to break down these three big Ideas we're going to talk about sky and digital companionship we're going to look at the future of generative AI based on the current trends and the releases from Google and open Ai and then finally we're going to talk about our capitalization strategy how you and I can take advantage of this incredible technology we're going to explore and exploit the possibilities of these Technologies if these ideas sound interesting to you stick around we're going to do a quick Deep dive into each one of these topics if they don't GG well played peace so let's talk about Scarlet sorry let's talk about sky and digital companions versus AI assistants so first off if you haven't tried sky or any one of the other voices definitely give it a shot right now if you're using a Mac definitely download the Mac app it's been really really incredible to use and this technology is going to change the way we interact with our computers and with information so what's the difference why do we care about the delineation between digital companion and the AI assistant so here we have the AI assistant and here we have the digital companion how are these different it's very clear that digital companions are a super set of AI assistant personal AI assistants are great at tasks they're digital workers and essentially they can create read update and delete data on your behalf this is a really really powerful idea a really really powerful tool that is still coming into fruition and is still developing I don't want to undercut the importance of the personal AI assistant we started building our own called Ada on the channel as I started building it and sharing it I quickly realized there's a ton of value here and someone is going to innovate on the space what do you know a few weeks later we have Sky built on gbd4 Omni completely gamechanging and what they're doing is absolutely incredible they've dropped the UI they added the voice they dropped the latency they added memory and they added emotion digital companions can convey emotion they have the ability to understand you they have connection they have memory and they're built to create relationships with you open AI is going for your head and your heart so to speak and it's a brilliant strategy so there's a massive difference here I hope you can see it personal AI assistants although extremely valuable they lack all of the things that make a relationship that make a partnership that make a team really great right they lack emotion understanding connection memory and the ability to build concrete relationships digital companions have all of that this is why the release of Sky specifically on chat GPT on top of the GPT 4 Omni model with that crazy low latency is so groundbreaking Google has their own version via project Astra it looks like and and this is just really going to change everything it's going to change how we work it's going to change how we interact with our data I do want to shout out and we'll talk about this a little further in the video we have to be really careful about where this relationship goes the digital companion is a hyper killer use case for generative AI as soon as open AI drops support for gbg4 audio cont content we're going to be integrating that into Ada our personal AI assistant and we're going to be seeing what type of capabilities we can get out of that hit the like and hit the sub if you want to see how you can build your own personal AI assistant and potentially digital companion based on how good their API is I'm really excited for that we're going to cover that on the channel as soon as that drops so let's talk about the future of generative AI so if you want to predict the future of llm technology and really anything in general I think it's important to do the following things observe the crowd follow the money have have a concrete opinion make several bets and then reflect and repeat in both failure and loss cuz you're not going to get everything right making predictions and looking at the future is hard and you're going to lose but that's how you improve and I think it's really important especially when the ground is so shaky to be making predictions following up with them making bets and observing where everyone is focused this is how we've been able to kind of get ahead of the curve a little bit on the channel we're always looking where things are going we're looking at where the money is going we're looking at the problems being solved by big Tech and by open Ai and then we create concrete opinions and bet on them I think this is really important for attempting to predict the future you don't want to be following the crowd exactly you want to be observing the crowd seeing what everyone is doing and then making your own opinion have an individual opinion so where where does this take us right so let's look at the future of generative AI based on the trends that it looks like open Ai and Google are setting for us these are clearly the top two players in gener of AI what were they betting on where are they trying to lead us Engineers where are they putting their money so these are the standout items from their respective presentation we have dbd 40 the API supports coming with audio support and then we have Chad gbt of course with Sky built on Omni Gemini put out a ton of bangers as well they also put out project Astro which had really really really crazy response times everything Google release was slightly overshadowed by open ai's release but nonetheless there's a lot of valuable things and more importantly I think there's a lot of value in looking at where they're spending their time their money and what they're presenting to us right so where does this take us what predictions can we try to draw for the future of generative AI based on their releases these items are pretty clear right A lot of these are obvious but there are a few here that I really want to point out faster models are a big big deal gbd4 Omni and Gemini flash point to that directly it's vitally important to get the models faster the faster the model is the lower the latency the more you can do with it and The Wider the use cases get the big big winners here from both presentations multimodal I think a another hugely emerging trend is going to be just really fast cheap access to image and video generation this will revolutionize uh information on the internet and in both positive and extremely negative ways really want to highlight the idea of the digital companion this is something that Sam Alman has pointed out several times he has struck absolute gold here another huge shout out that I haven't seen many people talking about is context management Gemini and Gemini Pro in addition to upping their context window to 2 million tokens a mindboggling 2 million tokens they also pitch this idea of having context caching so that you can kind of load a session so say you're going to write code on your you know 1 million line code base you can context load your entire code base and then just ask questions and generate code based on your hot loaded context cach and apparently that's going to be cheaper and more effective than using the entire context window every single time we do need to see the prices come down for huge context prompts I like to call them baps or big ass prompts but I thought this was a really really interesting idea big Tech specifically Google is tackling this context Problem by introducing interesting context management uh paradigms and techniques so I think these are really clear Trends let's talk about what we can do with this right so what's our capital ation strategy how can we take advantage of this incredible technology so I think it's really important to call up this one thing um throughout all of these changes one thing has been extremely consistent The Prompt isn't going anywhere you should be prompting everything everywhere all the time prompt texts prompt blogs prompt code prompt images prompt videos literally prompt everything if you're not prompting assets that you're generating for your job for your work for your tools um I think it's pretty easy to say you're leaving gains on the table and you're not fully utilizing generative AI to its full capacity we put out a whole video on how to prepare for the next 100x model the GPT 5 GPT 6 whatever is coming next I highly recommend you check that out I wouldn't spend too much time um prompt engineering on cheaper models specifically for all the reasons mentioned right they're getting faster they're getting cheaper accuracy is getting increased and the context window is increasing there's still definitely a a really strong use case for a bunch of different prompt chains to drive outcomes and drive results that you know ultimately create agentic workflows but I wouldn't spend too much time uh prompt engineering on cheaper models specifically on the more expensive models if you need to push them with some more intricate prompt chains I definitely say go for that I spend a decent amount of my time doing that right now I would say if you don't have to which I completely understand if you do if if you know the cheaper models are all that's available to you just you know keep grinding keep hitting it otherwise I would say don't spend too much time trying to save money on the cheaper models uh get that practice in get your reps in spend the time spend the money to understand the maximum capabilities of the top-of-the line models and of course right now we're talking about gbd4 Omni all right so I've been saying this on the channel for a while drop rag use baps use big ass prompts fill up your context window create context filled prompts again I'll link that video in the description where we talk about this more I've been saying this for months as soon as I started seeing all these rag oriented startups pop up and uh people just spending way way too much time on this guys this problem is going to be solved by the larger context window and these interesting context Management Solutions don't waste your time on rag I know I'm going to get some push back for this one I highly doubt that a million to two million tokens isn't doing the trick right now so anyway drop rag use baps you know this is a you know kind of a a social statement maybe more than anything but I think it's really important to build a work oriented relationship with your digital companion I'm not going to harp on this one too much but uh I I think over the next few years you know we're going to see some really weird kind of interesting relationships develop I've already found myself you know weirdly feeling connected to Sky to our conversations to Building Technology together to you know discussing making progress together exploring ideas asking questions um it is truly incredible to have a digital companion in your pocket that can help you solve nearly any problem or at least can help you work through the problem but I think it's really important to build a work oriented relationship with your digital companion because if you don't uh things are going to go south really quickly I'm not sure any great company can resist the revenue potential of selling your data of selling your information it's too great of an opportunity to sell ads against so I would be really careful here we already have these weird kind of parasocial relationships developing uh with twitch streamers and YouTubers and you know other types of online Internet relationships um I think we should be really careful about what comes next which is these what I like to call digit social relationships which is you know just like I said us feeling more connected to our you know digital companion that's helping us get a ton of work done you know feeling more connected to Sky than you know than anyone else in our our life and other relationships so and I know that sounds a little crazy especially if you have a lot of stable relationships in your life but um I think this is something to really watch out for focus on building that work oriented relationship nothing else because you know the these digit social relationships will be very exploitative if and when open AI starts selling your data and starts selling your emotions that makes for crazy crazy ad targeting so anyway just want to shout that out I just want to make sure we're kind of you know looking out for each other a little bit at least in that way because this technology although extremely powerful can be extremely exploitive all right so what's next I think that this is a really powerful idea your data and your ux is now your most valuable asset the cost of text is going to zero the cost of codee is going to zero images going to zero video going to zero everything the cost of any asset is essentially going to zero minus your data and your user experiences that you can build right just like it's always been your ability to truly solve a problem for your users for yourself for your job for your work um this is your most valuable asset now right it's it's that fine-tuned Niche solution so focus on that focus on your data and your user experience right right and take that and plug it into these systems right plug it into your prompts plug it into your digital companion plug it into your personal AI assistant I think this is where all the real value is now as we move into a world of hyper fast hyper cheap hyper accurate multimodal models and lastly of course um this is kind of an obvious dumb one to add but I just want to add it uh open AI is clearly leading here I'm I'm going to say you know just keep an eye on them keep an eye on gpg 40 I'm going to be creating content I'm going be creating videos on their API support for audio as soon as that comes out I think this is going to be a great way to enhance adaa the personal AI assistant we've been building on the channel it's just a big call out there I think Google's coming out with a lot of great stuff too I'm keeping an eye on them as well but it's kind of clear to me that open AI is in the lead and in a more novel way in the lead all right so that's that let's end with this full circle kind of idea why did I say at the beginning that these benchmarks are a little fishy right we have some fishy benches here it comes down to a couple different things don't get too far ahead Sam Alman and open AI have talked about this idea of doing more iterative rollouts so that us and Society can more easily adapt and you know just kind of take time to catch up and understand and utilize and internalize this incredible AI technology but but if we look at these benchmarks in a little more detail um I noticed something weird and it kind of pushed me to make a hypothesis about why these benchmarks are like this look at just how much better this was than gp4 just barely better right even worse in this scenario I think if you take that into account and you look at the super alignment team uh kind of Dipping out you know when we're talking about making predictions following the money not following the crowd I think only one of two things can be true um the first case is that we are actually starting to hit a a ceiling with the performance of gbt models maybe I put that at 30% 30% likely of all the scenarios and the second scenario I think is a lot more likely and it really does line up with this idea that they have been talking about that Sam's been talking about with the iterative roll outs right don't get too far ahead let people catch up and that's that what we're actually looking at here gb40 is actually a watered down version of gb5 right it's a literally a gbt 5 with uh one of its legs cut off that's kind of extreme in graphic but you get what I mean right it's a watered down lighter version of GPT 5 that's just barely beating right because you would want to show this off if you release a product um you want to show that yes it's an improvement not a massive Improvement we have some really big exciting stuff coming you know to me this this looks this looks engineered almost to me right these benchmarks were just so close either we are actually hitting a GPT limit and you know there's just no more data to train on and the size of the model is starting to level out and uh the performance is starting to level out I'm having a little fun with the prediction there let me know what you think in the comments do you think that this is a water down version of GPT 5 or do you think that we really are hitting the limits of what we can do with this architecture of gpts if you enjoy the video you know exactly what to do hit the like hit the sub and uh it's time to get to work hey Sky you ready to build absolutely what are we building today all right guys I'll see you in the next one",
  "timed_transcript": null,
  "youtube_metadata": {
    "source": "youtube-transcript-api"
  },
  "llm_outputs": [
    {
      "output_type": "tags",
      "output_value": "digital-companion, generative-ai, multimodal, context-management, prompting",
      "generated_at": "2025-11-17T22:26:41.826798",
      "model": "claude-3-5-haiku-20241022",
      "cost_usd": 0.001,
      "prompt_tokens": null,
      "completion_tokens": null
    }
  ],
  "derived_outputs": [],
  "processing_history": []
}