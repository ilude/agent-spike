{
  "video_id": "fd7hvE0EG_c",
  "url": "https://www.youtube.com/watch?v=fd7hvE0EG_c",
  "fetched_at": "2025-11-09T23:15:23.023339",
  "source": "youtube-transcript-api",
  "import_metadata": {
    "source_type": "bulk_channel",
    "imported_at": "2025-11-09T23:15:23.023339",
    "import_method": "cli",
    "channel_context": {
      "channel_id": null,
      "channel_name": null,
      "is_bulk_import": true
    },
    "recommendation_weight": 0.5
  },
  "raw_transcript": "Can this agent mode go rogue? The answer is yes. And Sam Alman himself warned about it. He said, \"I would not use this for email triage because someone, and he tweeted this on Maine, someone could write an email to me with a prompt that agent mode would read when it opened the email and that prompt would hijack agent mode.\" That is a new form of prompt injection. That is a new form of attack, an email as a prompt injection attack. Well, if we weren't thinking it before, Sam, we're sure thinking it now. Thanks for giving everybody the idea there. He's right. That is absolutely a way you could prompt inject and hack these operator mode agents. And the challenge is you can do that with other websites, too. You can put text at lower contrast that humans are not going to notice that an agent might notice.",
  "timed_transcript": null,
  "youtube_metadata": {
    "source": "youtube-transcript-api",
    "video_id": "fd7hvE0EG_c",
    "title": "ChatGPT Agent Mode Prompt Injection Attack  #artificialintelligence #ai #shorts",
    "description": "My site: https://natebjones.com\nMy substack: https://natesnewsletter.substack.com/\n\nTakeaways\n 1. Hype vs Reality: Agent Mode behaves like an \u201cover-thinking intern,\u201d delivering less autonomy and speed than the marketing suggests.\n 2. Excel Automation Edge: Its most credible win is auto-building straightforward Excel models, finally closing AI\u2019s long-standing spreadsheet gap for finance teams.\n 3. Mandatory Babysitting: Heavy guardrails force constant user approval, slowing work and revealing OpenAI\u2019s priority to limit liability over efficiency.\n 4. Prompt-Injection Risk: Sam Altman admits a simple email can hijack the agent\u2014spotlighting a new, highly exploitable attack surface.\n 5. Data-Harvest Strategy: OpenAI is shipping early to collect real-world usage data, effectively turning users into test subjects for a decade-long general agent project.\n 6. Specialized Beats General (for now): Narrow, task-focused agents\u2014like code or calendaring bots\u2014still deliver more day-to-day value than this broad but cumbersome tool.\n\nQuotes\n\u201cWe are all guinea pigs in OpenAI\u2019s decade-long quest to build a general-purpose agent.\u201d\n\u201cAll you get when you give deep research arms and legs is an over-thinking intern.\u201d\n\u201cAn agent I have to babysit isn\u2019t an assistant; it\u2019s another task.\u201d\n\nSummary\nI argue that OpenAI\u2019s new Agent Mode, despite the hype, behaves like an over-thinking intern: it can build simple Excel models and rudimentary decks but demands constant supervision, slows work, and invites liability. Guardrails force repeated hand-offs, and Sam Altman admits the system remains vulnerable to prompt-injection hijacks, making email triage risky. Finance professionals may glean value from automated spreadsheet creation, yet most users will see limited day-to-day payoff. OpenAI is effectively using us as guinea pigs to gather data for a decade-long quest toward a true general-purpose agent; until then, specialized task-focused agents will deliver more practical gains.\n\nKeywords\nOpenAI, Agent Mode, general-purpose agent, Excel automation, guardrails, prompt injection, supervised AI, finance workflows, intern analogy, data collection, Sam Altman, liability, specialized agents",
    "published_at": "2025-07-18T17:47:57Z",
    "channel_id": "UC0C-17n9iuUQPylguM1d-lQ",
    "channel_title": "AI News & Strategy Daily | Nate B Jones",
    "duration": "PT53S",
    "duration_seconds": 53,
    "view_count": 3444,
    "like_count": 92,
    "comment_count": 6,
    "tags": [],
    "category_id": "22",
    "thumbnails": {
      "default": {
        "url": "https://i.ytimg.com/vi/fd7hvE0EG_c/default.jpg",
        "width": 120,
        "height": 90
      },
      "medium": {
        "url": "https://i.ytimg.com/vi/fd7hvE0EG_c/mqdefault.jpg",
        "width": 320,
        "height": 180
      },
      "high": {
        "url": "https://i.ytimg.com/vi/fd7hvE0EG_c/hqdefault.jpg",
        "width": 480,
        "height": 360
      },
      "standard": {
        "url": "https://i.ytimg.com/vi/fd7hvE0EG_c/sddefault.jpg",
        "width": 640,
        "height": 480
      },
      "maxres": {
        "url": "https://i.ytimg.com/vi/fd7hvE0EG_c/maxresdefault.jpg",
        "width": 1280,
        "height": 720
      }
    },
    "fetched_at": "2025-11-15T19:25:23.045612",
    "all_urls": [
      "https://natebjones.com",
      "https://natesnewsletter.substack.com/"
    ],
    "blocked_urls": [],
    "content_urls": [
      "https://natesnewsletter.substack.com/"
    ],
    "marketing_urls": [
      "https://natebjones.com"
    ],
    "url_filter_version": "v1_heuristic_llm",
    "url_filtered_at": "2025-11-15T19:52:17.491430"
  },
  "llm_outputs": [
    {
      "output_type": "tags",
      "output_value": "prompt-injection, ai-safety, ai-agents, cybersecurity",
      "generated_at": "2025-11-09T23:15:37.274867",
      "model": "claude-3-5-haiku-20241022",
      "cost_usd": 0.001,
      "prompt_tokens": null,
      "completion_tokens": null
    }
  ],
  "derived_outputs": [],
  "processing_history": []
}