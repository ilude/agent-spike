{
  "video_id": "SykH1k65Dy4",
  "url": "https://www.youtube.com/watch?v=SykH1k65Dy4",
  "fetched_at": "2025-11-09T23:53:53.776196",
  "source": "youtube-transcript-api",
  "import_metadata": {
    "source_type": "bulk_channel",
    "imported_at": "2025-11-09T23:53:53.776196",
    "import_method": "cli",
    "channel_context": {
      "channel_id": null,
      "channel_name": null,
      "is_bulk_import": true
    },
    "recommendation_weight": 0.5
  },
  "raw_transcript": "So, Mary Maker wrecked my weekend, and I mean that in the best sense. She's known as the queen of the internet. Uh, and she was famous for her internet trends reports that came out annually and were particularly insightful from the 1990s to 2019. She was early on Google, she was early on Amazon. She has a sterling reputation for her analysis in the space. This is the first report she has dropped in five years and it's on AI. 340 slides. I'm guessing you don't want me to go slide by slide, so I want to call out to you some of the highlights. There is a completely free article over on my Substack if you'd like a full takedown. Uh it was a lot of fun for me to go through this weekend. I I it's it's incredible to see the amount of due diligence in this deck to be very honest with you. All right, let's get right to it. First up, we have what I call the up into the right section. uh where Mary is basically laying out the case that AI is absolutely unprecedented in the rate of growth that it is demonstrating across all of the traditional metrics and software. So she calls out AI user growth chat GPT as an indicator up 8x in 17 months which is just wild. uh so up to 800 million and then talks about how that translates into revenue and these are already given the pace of change these are already somewhat out of date um and revenue is up toward 4 billion now for chat GPT subscribers are up toward uh 20 million uh from virtually zero uh in 2022 and so it's just again been up and to the right and continuing to accelerate even in 2025. Uh, and then this one is my surprise. The time to 365 billion annual searches or a billion searches a day. Chat GPT got to that 5 and a half times faster than Google got to it. And so Mary calls out that Chat GPT hit 365 billion annual searches in 2 years versus Google's 11 years, which is just wild. And now I know there's differences in internet penetration and other things that affect that but still the speed is astonishing. Mary also calls out uh some up and to the right trends in capital expenditure and internet infrastructure. Nvidia installed GPU computing power has gone up 100x in six years. 100x. That one also got me to do a double take. There were a lot of double takes in these slides because I knew the numbers were big, but it was just wild. Capex spend at the big six, I knew that was inflecting. It's really astonishing how much it has scaled up as a growth rate since 2020. Like we can see the beginning of the AI buildout in big cloud providers in 2020. Data center buildout also had a major inflection point but came a little bit later in 2023 as AI start to hit. It's been up 49% a year since 2023 which is insane. At the same time, there are a few charts that are down and to the right. So energy required per LLM token. I I am not kidding you. 105,000x decline in energy required to generate a token over the last decade. If you want to look for a reason why some of what we're experiencing today is possible. That's it. 105,000 times cheaper to generate a token in the last 10 years. This is off the NVIDIA GPU set. Similarly, AI inference costs are dropping through the floor. So uh the cost to serve a model is 99.7% lower over two years. AI cost efficiency gains look like a cliff as you would expect. And Mary does an interesting job here on this slide. She talks about the difference between the light bulb and the computer chip and or computer memory chips in particular and then uh the cost to generate like a 75word response in chat GPT and you don't have to like know the exact number to get the general idea that the light bulb took something close to 75 years to drop as far in cost as chat GPT has dropped in two years. And that's just wild to me. And because cost is lower, model performance is converging. And this is why Deep Seek's gains are not that surprising. And so if you look at the overall arena scores, which I know are not perfect, but at least they're a head-to-head comparison. Google, Open AAI, Deepseek, they've all converged, and they were very, very different just a year plus ago. And so seeing that convergence highlights what Sam has called out which is that we don't live in a world where we're going to have one winner in AI. We live in a world where there are multiple winners in AI. There's fierce competition. And this calls out one of the areas where Mary and I diverge a little bit. Mary views this fierce competition in classically economics terms. She thinks of it as competition that's good for consumers. What I notice is that consumers seem to have already anointed a winner in chat GPT and to a lesser extent Gemini and I don't see a proliferation of apps powered by these foundation models that I would expect in a true consumer revolution. People seem to be leaning into the habit stack they already have with Chad GPT. I do think this sort of vicious competition is going to be very good for businessto business use cases where we see much wider adoption across different business use cases and lanes of these different models. And so I think the thing that stands out to me that Mary doesn't really get into in the deck is that there's a very different future unfolding empirically for B2B than there is for B TOC. B TOC seems like a lottery where you're competing with shed GPT right now and B2B looks a lot more like we have these individuated use cases foundation models won't necessarily ever cover them we need to build a particular tool for this particular use case and you can have a lot of winners in the in the niches and the margins there and in that world having lower overall model cost and cost to serve makes a big difference from a unit economics perspective. Now, that gets at one of the things that Mary calls out that isn't really it's not clear how this gap gets fixed. Fundamentally, AI model companies have raised something close to hundred billion. Mary pegs it at 95 billion and they only cleared about 11 billion in annualized revenue. Now, that number is rising really fast as these model makers start to scale. I think Anthropic literally is off the charts right now because Mary pegs them at 2 billion and I recently heard three billion as an annualized rate. So they're really exploding, particularly since the Claude 4 launch a couple of weeks ago, but the overall picture remains the same. They've raised about 10 times more than they've delivered in annualized revenue. And there's a tremendous capital overhang there. And that means that means a big question mark around how we resolve that funding discrepancy. Because if you have a capital overhang, you have vicious competition, you have cost to serve going down, there's tremendous margin pressure on uh token utility and cost per token. At the end of the day, you've got something that you are selling that's depreciating really fast. That's tokens. And it costs a lot to make a new model. And I don't know how you clear money on that long term. And I think that's one of the interesting question marks for Anthropic, for OpenAI, for Google. And of those, Google obviously has the deepest pockets and can sustain this the longest. And that may be part of their strategy. But at the end of the day, this is a real discrepancy. And and the bill is going to have to be paid at some point. I remember when Uber was dirt cheap and everyone was taking $2 rides here and there. Well, now they're $20. Now they're $25 rides. And so part of how Uber closed their profitability gap was they started charging the economic price. And I do wonder if at some point model makers are going to close this revenue gap by substantially raising prices and we will have to see if they're able to retain users in that scenario. All right, moving along a little bit. I think one of the other takeaways I had is that AI agent interest is up as much as people think. It's up a,088% over the last 16 months if you look at Google search trends. But, and this is again where I would sort of add a little nuance to Mary's take, I do not think that we are seeing very many practical use cases of agents outside of very large companies that have strong LLM engineering teams or very tidy pre-built agents that do very narrow things. Those are the two use cases where I see wins. And there's a big messy middle in the mid-market where companies have custom needs, but they don't have the capital to get strong AI engineering talent. And their needs are too custom for the pre-built stuff. And what do they do? There's not really a great answer to that right now. Uh, and I think that that's an area where a little bit more nuance is helpful in terms of understanding what's really going on. All right, we're going to skip over some of this. I know we've already gone on a long way. One thing I do want to call out is that it's not just you imagining everyone talking about the AI hype. Uh the proportion of S&P 500 firms mentioning AI during their quarterly earnings calls is now over 50%. It has skyrocketed from 10% in just a year, year and a half maybe. Absolutely wild. And there has been a doubling in developers and startups and apps in the NVIDIA AI ecosystem to serve all of those companies. And so in a sense, we're in the middle of a gold rush. And she actually names it. Mary Mary calls out sort of that famous venture capital analogy of selling picks and shovels in the gold rush. And uh there's a whole run of about 10 or 15 slides where she does nothing but talk about like the companies that are selling chips and monetizing really effectively. a lot of her case is that selling tokens has it's a low margin business but selling chips is a high margin business so she likes Google for their TPUs she likes uh obviously Nvidia and kind of how they've been able to manage their business and we will have to see how the major model makers handle their monetization strategy okay we've gone through a lot of the deck but I've gone through it at a very high level and I know this may seem like a long video but I promise you reading 340 slides is longer. If you want to dive deeper on this, uh, feel free to grab my Substack. I'll link it here. It is a full readout. Still much shorter than the deck, but you get a sense of what she did. You can check out all of those charts. I chose not to scroll through it because whenever I do that, I never get views on those videos. So, you guys seem to like my face, which is kind of weird, but here we are. And you can also see my take on the deck. And you can see a little bit more about the taker on the internet. I include sort of perspectives from Axios, perspectives from other places where Mary has given interviews. Uh, and we sort of get an overall picture of this deck. Is it worth it? Yes. This is probably the deck that will be most influential to how capital allocators, VCs, investors think about AI for the rest of this year. It is absolutely worth this degree of attention. And if you're not an investor, it's worth it to you because this shapes how the investors who drive companies, drive job creation are going to be thinking about this stuff. And that affects all of us. Whether the job opens up or not is the function of whether the startup funding is there. And if the startup funding is there, it might be because Mary Mer made a recommendation in this deck very bluntly. And so I want to make sure everybody is aware of this. I've made this completely free so that everybody can dive in and look at it. Uh, and I've obviously linked to the deck so that you can sort of see the full thing if you want to. And that's where I'll leave it. It was a lot of fun for me to go through all 340 pages of the deck. I know it's not fun for everybody, but I'm a nerd like that. Hope you enjoy this summer.",
  "timed_transcript": null,
  "youtube_metadata": {
    "source": "youtube-transcript-api",
    "video_id": "SykH1k65Dy4",
    "title": "I read Mary Meeker's 340 Slide AI Deck\u2014Here Are the Top Takeaways",
    "description": "The deck: https://www.bondcap.com/report/tai/#view/3\nThe substack: https://open.substack.com/pub/natesnewsletter/p/i-summarized-mary-meekers-incredible?\n\nMy site: https://natebjones.com/\nMy links: https://linktr.ee/natebjones\nMy substack: https://natesnewsletter.substack.com/\n\nTakeaways:\n 1. Unprecedented Adoption Curve: ChatGPT vaulted to 800 million users and 365 billion annual searches in just two years\u2014five times faster than Google\u2019s early climb\u2014showing AI\u2019s break-neck consumer uptake.\n 2. Infrastructure Arms Race: NVIDIA-powered GPU compute has risen 100\u00d7 since 2019, while Big Six cloud CapEx and data-center spend have surged, fueling the backbone of the AI boom.\n 3. Costs Fall off a Cliff: Energy per LLM token is down 105,000\u00d7 and inference costs 99.7 % in two years, unlocking new use cases and shrinking barriers to entry.\n 4. Model Performance Converges: Arena scores now cluster OpenAI, Google, and DeepSeek, signalling a \u201cmulti-winner\u201d landscape rather than a single dominant model.\n 5. Funding vs. Revenue Mismatch: Model builders have raised \u2248 $95 billion against only \u2248 $11 billion in annualized revenue\u2014an overhang that may force higher prices or new monetization plays.\n 6. Diverging B2B vs. B2C Futures: Consumers gravitate to ChatGPT, but B2B remains wide open for niche, high-value tools that leverage cheaper tokens and specialized workflows.\n 7. Agent Hype, Sparse Reality: Searches for \u201cAI agent\u201d are up 1,088 %, yet real deployments thrive mostly inside deep-pocketed firms or tightly scoped products, leaving a mid-market void.\n\nQuotes:\n\u201cChatGPT reached 365 billion searches in two years\u2014five and a half times faster than Google ever did.\u201d\n\u201cIt\u2019s now 105,000 times cheaper to generate an LLM token than it was a decade ago.\u201d\n\u201cModel makers have raised ten times more capital than they earn today, and sooner or later that bill comes due.\u201d\n\nSummary:\nMary Meeker\u2019s first report in five years lays out AI\u2019s breathtaking acceleration. I walk through her 340-slide deck, noting ChatGPT\u2019s explosive user growth, massive hardware build-out, and plunging costs. GPU compute is up 100\u00d7 since 2019 while energy per token has fallen 105,000\u00d7, letting model performance converge across OpenAI, Google, and DeepSeek. Yet model vendors face a $95 billion funding overhang versus $11 billion in revenue. Consumers already favor ChatGPT, but I see richer opportunity in B2B niches and infrastructure \u2018pick-and-shovel\u2019 plays. Hype around agents is real, adoption less so. Investors will treat this deck as this year\u2019s AI compass.\n\nKeywords:\nMary Meeker, AI trends, ChatGPT, user growth, GPU compute, token cost decline, model convergence, capital overhang, B2B AI, AI agents, pick-and-shovel, Nvidia",
    "published_at": "2025-06-02T18:09:37Z",
    "channel_id": "UC0C-17n9iuUQPylguM1d-lQ",
    "channel_title": "AI News & Strategy Daily | Nate B Jones",
    "duration": "PT12M59S",
    "duration_seconds": 779,
    "view_count": 45388,
    "like_count": 1726,
    "comment_count": 114,
    "tags": [],
    "category_id": "22",
    "thumbnails": {
      "default": {
        "url": "https://i.ytimg.com/vi/SykH1k65Dy4/default.jpg",
        "width": 120,
        "height": 90
      },
      "medium": {
        "url": "https://i.ytimg.com/vi/SykH1k65Dy4/mqdefault.jpg",
        "width": 320,
        "height": 180
      },
      "high": {
        "url": "https://i.ytimg.com/vi/SykH1k65Dy4/hqdefault.jpg",
        "width": 480,
        "height": 360
      },
      "standard": {
        "url": "https://i.ytimg.com/vi/SykH1k65Dy4/sddefault.jpg",
        "width": 640,
        "height": 480
      },
      "maxres": {
        "url": "https://i.ytimg.com/vi/SykH1k65Dy4/maxresdefault.jpg",
        "width": 1280,
        "height": 720
      }
    },
    "fetched_at": "2025-11-15T19:27:15.878932",
    "all_urls": [
      "https://www.bondcap.com/report/tai/#view/3",
      "https://open.substack.com/pub/natesnewsletter/p/i-summarized-mary-meekers-incredible",
      "https://natebjones.com/",
      "https://linktr.ee/natebjones",
      "https://natesnewsletter.substack.com/"
    ],
    "blocked_urls": [
      "https://linktr.ee/natebjones"
    ],
    "content_urls": [
      "https://open.substack.com/pub/natesnewsletter/p/i-summarized-mary-meekers-incredible",
      "https://natesnewsletter.substack.com/"
    ],
    "marketing_urls": [
      "https://www.bondcap.com/report/tai/#view/3",
      "https://natebjones.com/"
    ],
    "url_filter_version": "v1_heuristic_llm",
    "url_filtered_at": "2025-11-15T19:52:25.150147"
  },
  "llm_outputs": [
    {
      "output_type": "tags",
      "output_value": "{\n  \"video_title\": \"Mary Meeker's AI deck analysis \u2014 growth, costs, and monetization\",\n  \"tags\": [\"ai-economics\", \"ai-infrastructure\", \"ai-competition\", \"b2b-ai-use-cases\", \"ai-monetization-strategies\"],\n  \"summary\": \"A take-through of Mary Meeker's AI deck, highlighting exponential growth, infrastructure cost declines, market competition, and implications for B2B use cases and monetization.\"\n}",
      "generated_at": "2025-11-09T23:54:04.295072",
      "model": "claude-3-5-haiku-20241022",
      "cost_usd": 0.001,
      "prompt_tokens": null,
      "completion_tokens": null
    }
  ],
  "derived_outputs": [],
  "processing_history": []
}