{
  "video_id": "pEYnFLnz_vI",
  "url": "https://www.youtube.com/watch?v=pEYnFLnz_vI",
  "fetched_at": "2025-11-09T22:49:01.613308",
  "source": "youtube-transcript-api",
  "raw_transcript": "You need to be at a point with your teams where they know the outputs that AI needs to write, build, demonstrate to show that it has done the work. In other words, with this model, with chat GPT5, it does better if you force it to prove its work than if you tell it to do the work. So, in other words, when you're asking for the output, say, \"Hey, give me the sentiment analysis. give me the Python workbook to show how you did it and then also give me a plain English summary of the rubric and the scoring assessment that you used for the sentiment analysis along with any personas that you developed. Something like that, right? Like basically show me what you did. Sure, give me the executive summary and the report, but show me all the artifacts along the way as well and demand those as outputs.",
  "youtube_metadata": {
    "source": "youtube-transcript-api"
  },
  "llm_outputs": [
    {
      "output_type": "tags",
      "output_value": "{\n  \"video_title\": \"ai prompts should show their work\",\n  \"tags\": [\"prompt-engineering\", \"explainable-ai\", \"sentiment-analysis\", \"data-science-workflow\"],\n  \"summary\": \"A discussion on prompting AI models to reveal the steps, artifacts, and evaluation rubrics behind outputs, including sentiment analysis and notebooks.\"\n}",
      "generated_at": "2025-11-09T22:49:13.626926",
      "model": "claude-3-5-haiku-20241022",
      "cost_usd": 0.001,
      "prompt_tokens": null,
      "completion_tokens": null
    }
  ],
  "processing_history": []
}