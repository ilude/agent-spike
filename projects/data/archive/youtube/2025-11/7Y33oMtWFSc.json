{
  "video_id": "7Y33oMtWFSc",
  "url": "https://www.youtube.com/watch?v=7Y33oMtWFSc",
  "fetched_at": "2025-11-09T22:58:05.597132",
  "source": "youtube-transcript-api",
  "raw_transcript": "Hey everybody, I am Michael Cricggsman and I'm speaking with Nate Jones and this is Nate and Mike talk about AI tech. Hey Nate, how are you? >> We've never done this before. I'm excited. I mean, we've talked before. We've never done this before. >> Yeah. Well, this will be fun. Uh, you know, there's so much that's going on right now. So many changes. Uh, in the world of AI, there's a lot to cover. Maybe we should start with this Microsoft study that came out. They analyzed 200,000 chats uh inside Bing Gemini chats and or it's not Gemini. What is Microsoft's co-pilot? C-pilot. >> Yes. I get, you know, get them confused. So they analyzed 200,000 co-pilot chats and they came up with this set of jobs that are not likely to be changed and another set of jobs that are likely to be changed. >> And I have that and I can share my screen here. So take a look at this, Nate. Look at the top the top jobs. These are the ones that are most likely to be impacted by AI. >> I think it's a really fascinating list. Like I keep staring at the list and seeing new angles on it. As someone who looks at AI a lot, I think historians being number two is absolutely fascinating. Uh I I know historians who are over the moon about AI because it will change their jobs. In particular, it makes uh the process of reading primary sources much much easier. >> Yeah. Well, you know, you look at uh historians, interpreters, it's in a way, do you think there's anything surprising here at all? Actually, >> you know, if I were to draw up a list of the top sort of occupations across the economy, I don't think I would have put passenger attendance as number three. I think there's an implication that robotics is going to take off in a big big way here. Uh if you look at sort of what some of these roles entail, you have to be in a tightly constrained operating environment. You have to be able to operate safely at at altitude for the passenger attendance or in a manufacturing envir environment for some of the manufacturing roles that are listed here. They've got to be betting on robotics, right? >> Yeah. I mean the thing is passenger attendance is a is a kind of interesting one because you think about the role think think of a a flight the role that the flight attendant >> is playing. It's a lot more than just collecting a ticket. >> Yeah. >> On the other hand, if you think about a parking garage, there are many parking garages now that don't have an attendant anymore. They're fully automated. Most of the ones I end up parking at are fully automated now. >> So, you know, if you think about that, a passenger, if you consider that to be a passenger attendant, I think it's a perfect example of automation that will eliminate an entire class of jobs. And then people always say,\"All right, well, we're not just eliminating jobs. We are creating the opportunity for these employees to do higher value activities.\" >> Sure. >> But tell that to the person to the to the parking attendant. >> Right. It it becomes sort of uh CEO speak, right? where like it's something that is a convenient uh statement that you can make at the seauite level, but there's not necessarily true organizational commitment to actually help someone upscale, nor is there potentially interest in that all the time. Uh and this is all very interesting to me because at the same time as we're looking at this list of jobs, I know for a fact that there are jobs that sort of have true AI skills in them for which there are not enough people in the world. and people are absolutely desperate. I think that the the ridiculous pay packages that Mark Zuckerberg is throwing around is maybe the tip of the iceberg, but there's a whole world of jobs that are in that AI sphere that are all very much in demand. Um, and so I'm sort of reading those in my head as I look at this list as well. >> Yeah. Well, I guess the the uh question about the value of developers, AI developers, and there is there are such great sums of money that will acrue to the developers of AI products that obviously it's worth it for them to take that leave, leave that lead. I mean, there's such a potential massive shift that's going on in the world from, shall we say, nonAI to AI enabled product, services, robotics, you name it. >> Yeah. I I think there's there's like two or three distinct effects that I I haven't seen sort of laid out cleanly uh in a lot of places. I think one, the market for researchers and the market for engineers is distinct. Um, and the market for AI researchers is roughly 10x the market for engineers right now. So that the big pay package is getting thrown around. I think I saw a billion dollars in liquid comp thrown around for employees from thinking machines over the weekend which nobody took. Imagine saying no Mark Zuckerberg I won't take your billion dollars. Uh that's for AI researchers. It's not for engineers. Uh and that's because those are the people who are able to design the next models. They're able to be the pioneers. Engineers are also seeing strong demand especially in AI engineering spaces but I would say it's less of a 100x compensation world and more of a significant bump over current compensation world for them. Uh and what's interesting the third class that we don't talk about is that regular engineers that are good at their craft are seeing strong demand because the world of AI has made software really cheap and that makes polish at a premium and only good engineers can deliver polish. Well, that's um this is not much different from tra from traditional software development where the best developers you know I forget what the exact metric is 10x 20x the capability the efficiency the quality uh the ability to create code that actually solves the problem in the in a durable way. >> Right. Right. Exactly. And I think that that gets to this idea that we have had trouble measuring variance within a job for a long time. And it has never been more important to understand what are the factors that drive extraordinary performance within a particular job title and how do we encourage more of that. >> Hey, I just want to remind people that if you're watching, ask your questions. Um, this is the first time that Nate and I have done this kind of thing. So, we're still figuring it out, but you can ask your questions on LinkedIn. If you're not watching on LinkedIn, make your way to LinkedIn. You'll have to look for my personal profile and you can ask your questions there. It's a live event. And you can also ask on Twitter using the hashtag CXOT talk. And we welcome comments and questions from everybody. You know, I want to go back to this table and go down to the bottom. And when I say the bottom, this is the set of jobs that this study from Microsoft determined are the least likely to be replaced by AI. And so we have dredge operators, bridge and lock tenders, water treatment plant operators, >> floor sanders and finishers, >> pile driver operators. >> Yeah. Uh, apalmic medical technicians, which by the way is an interesting one because notice they don't say uh athometrists. No. >> Which medical medical jobs are among those that are likely to be replaced? Well, when we say that's now that's an interesting question, right? >> Disagree with you a little bit there and I think because of the liability piece, you cannot have a machine make a decision for which it's accountable in court and doctors can't. >> Okay. But I think that the way that will get handled is uh physicians will use AI enabled tools in a variety of ways. For example, >> I buy that >> right radiologists uh are have already well many fields have already started adopting these tools. Yeah. In in radiology, it's extraordinary that the AI can can pick out patterns of pathology in some cases more more rapidly and with with less more sparse information, less information than than a doctor. But >> and yet there is demand for radiologists like all of that automation, all of that AI enablement because I I've seen the same sort of studies and stories, it hasn't dampened demand for radiology at all. In fact, I was looking at the fact that radiology job demand is expected to rise. Well, to your point, the I think there's there's two issues. one to the to the point that you made which is the legal liability issue for sure these systems whether it's an active say independent robotic system which I don't think exists out in clinical practice today you know we're not sending robot robots out to operate on your eyes or take out your appendix uh yet these are these are all uh assistive systems operating getting under the control of a physician. >> Mhm. >> So in that case, of course, it's the physician who retains the liability. >> Yep. Yep. Exactly. >> So there so there's no liability issue there. But then to your to your second point, there is a trust issue. To what extent do we trust a diagnosis from a machine? >> And that is one of the most interesting um videos I ever made on TikTok, Michael, because I proposed the kind of what what I was assumed was intuitive. I said, you know what? Uh the machine may have good test scores on diagnosis, but I just don't trust it enough. I would rather have a human diagnose me. Sure, the human can ask AI for help. I'm fine with that. But I want the human to diagnose me. And I got comment after comment under that video basically saying, \"Nate, you're wrong. Nate, I want the machine to diagnose me because my doctor never listens to me.\" And I thought that was really interesting. Yeah, it's uh you know I I don't think the tools change the fundamental relationship between the doctor and the physician because at the end well you know I I'm going to interrupt myself. I was going to say at the end of the day it's the doctor that you have the relationship with. But let's fast forward a few years and we have uh yeah, >> you've taken some tests, you know, your blood tests and your cholesterol looks this and whatever, whatever, whatever. >> The doctor says, \"You're looking pretty good.\" You run that test through an AI that's accessible to you and it says, \"Nate, you have a potential issue here. It's not really visible yet, >> but I detect >> But I detect there's something going on and you need to do try this, this, and that test. >> Yeah. >> Does that break the bond of trust with you between you and the physician? >> I don't even think that's a couple years away. I know people who have those stories now where they are going and secondguessing the physician and they're going to AI and saying what do you think about this? Um like I will share for me I'm working on troubleshooting my sleep and I'm getting some perspective from a doctor but I'm getting a much more we'll call it a steady diet of ideas and perspectives grounded in data I feed it from my AI and it's helping me troubleshoot my sleep. Now, sleep is I guess you can say it's high stakes if you're a big believer in sleep. I'm trying to take it more seriously, but it's something that I feel good about asking for a second perspective from AI and not assuming that it's going to be the the beall endall. It's very useful. >> Yeah, I mean that's the thing is that these these tools are going to be uh profoundly useful. You know, let's take some questions. These are from LinkedIn right now. Uh, and again, everybody who's watching, thank you for watching. Put your questions in. This is literally the first time either Nate or I have ever done a kind of podcast like this. So, where we're taking questions and we're figuring it out. So, you're seeing us figure this out in real time as we go. So let's take some questions from LinkedIn here and pretty noran says so makes the comment that software product development firms and businesses down the line will have development architect and devops roles that are disrupted and downsized but business and product roles will survive and and PIT is asking Nate for your views. use. So again, she's making the argument that tech technical roles like like developers, architects, devops, they'll be disrupted and downsized, but the business and product roles will survive. >> I think that's such a fascinating take because I have heard that take and I have heard the exact opposite take that technical roles will do very well in the age of AI. I've heard the statement from, you know, engineers I deeply respect, uh, like Gurgly Oro that pulling out of engineering right now is like running away from carpentry when the table saw was invented. Like, don't do it now. This is going to be a great day. Um, and and that it's the business roles that are at risk. It's the product roles that are at risk because they're not adding real value in the age of AI. And so to to me, I think one thing I take away from that is that the value is definitely greener on the other side of the fence right now. Whether or not that's true, everybody thinks so. Uh, and what that underlines for me is that everybody feels the uncertainty whether you're in engineering or whether you're in product. And I think it's because we have a new general purpose technology. And so the technology is disrupting and changing these roles in different ways. And in particular, it is blurring role boundaries. And so when Andrew gave his uh talk uh I think it was uh a couple of weeks ago uh in the valley, he talked about how product management roles are changing. it just stuck with me. Uh one of the things he observed is that he is seeing a micro trend that is uh counter to the larger trend of like PMs uh managing larger spans. He's actually seeing some startups have PMs manage much smaller spans to the point where they're hiring two PMs per engineer uh which is insane and nobody has ever done that. And the reason why is simply to vibe code and manage the stream of ideas and bottleneck them for the engineer. So the engineer knows what to build with validation and so the PMs become validators and chief. But his point is that these PMs end up needing a relatively technical skill set. And he wonders and he's observed sort of in the companies he's an investor in if engineering backgrounded people are better prepared for that PM world than PM backgrounded people. And that's just been living rentree in my head as a concept for like the last two weeks. And it underscores how much change we have right now. >> Yeah. You know, I think another dimension to this is we have to break out technical roles and business roles in a in a more fine fine-tuned way. For example, >> Mhm. >> if we look at development tasks, there are certain development tasks that are let's let's call them wrote or nearly wrote those tasks. If you can if you can codify those, >> they're going away, >> right? And and you'll have the the manager of agents >> that you were kind of alluding to, right? But then you have create the creative roles which is not just technology architecture but this intersection of let's call it adaptability adapting the business into the lens of the technology to serve that business. >> Yeah. Yeah. I think that's a really interesting question and I don't think we've seen a lot of examples of that. like how do we h how do the business and the technology end up co-evolving so that we get to a place where the technology is more useful from a business perspective. I think actually one of the things that I heard just last night that illustrates that a little bit is uh you're familiar with at least the concept of cluey where you can sort of cheat at everything and you have the pane of glass up on your screen and nobody can see it etc. Well, we have the first major response back from a large company now. And you'd think that it would be a ban. Uh, but that's already been tried. No, the the response back uh and this is something that I caught out of a Mark Zuckerberg interview. He is going to explicitly permit students uh and job candidates taking interviews at Meta for coding roles to use AI in their coding exercises. He he wants them to because he needs that job skill at work. But and there is a catch. You're not doing it as far as I can tell on your own machine. You are coming in. You are going to be on site with them. You'll use meta machines. You'll use Llama. and he is going to measure whether you are copy and pasting responses or whether you are engaging and this is where that fine grain distinction comes in whether you are engaging critically with the the AI as a thinking partner in your development activities and and the people who can do the latter are obviously going to be the people who score better. Uh, and so in a sense it's kind of like I see it as an arms race response like people are using AI so much that the response is well we do need you to use AI but this is how we're going to measure whether you do it well. >> Yeah. This whole question of AI measurement. Let me bring something else in here that I think is relevant. So I get pitched a lot or people who want to be a guest on CXO talk. I'm sure Nate you must get pitched endlessly too in one way or another >> for different things. Yes. >> For different things but one you know people they they they want something and a lot of people want a lot of things. Okay. So so I got pitched a lot and I got pitched a senior executive from one of the largest insurers healthcare insurers in the United States. And I'm not going to say which one. and they pitched me to explain how they're using AI to improve healthcare. >> Okay, >> now that sounds pretty good, right? On the surface, we're going to use we're using algorithms and AI, but but here's the thing. >> I have been researching this topic and I've been watching a lot of Tik Tok videos. Okay, now everybody knows I'm addicted to Tik Tok, >> including your Tik Toks, Nate. I have an anonymous Tik Tok account so nobody knows who I am. So >> Oh yeah, you you can lurk on my my Tik Tok, right? >> Yeah. And you have a lot of impersonators on Tik Tok. >> I am working on that. Uh anyway, so so there are physicians out there who are describing in real detail the downstream problems caused by the AI and by these algorithms which are we all know that AI is a driver of efficiency. Well, if you're an insurer, what does efficiency mean? It means identify identifying claims that you can deny >> more efficiently. Yes. >> More efficiently. Do a better job. Come up with reasons. So where does that fit into this world? >> In a sense, I see AI as the great accelerator, Michael. Uh it accelerates the behaviors that we are already aimed at from a corporate perspective. Uh and if your corporate goals are aimed at setting up more solar installations, it's going to accelerate that. If they're aimed at selling more B2B SAS, it's going to accelerate that. If they're aimed at denying more claims, well, it'll it'll also accelerate that. Uh and that there there in lies the risk of a new technology is that you can use it for ends like that. Yeah, I you know and it's funny. So I said to these guys uh again I'm not going to say who it is. I said to them I welcome you as a guest on CXO talk but we can't just talk about the technology. We also have to you we have to discuss the the downstream use the environment the context in which that technology is used. Mhm. >> And as a technologist and CXO talk and you we're all we're all technologists here. >> We tend to think of technology as being neutral. But what is the intention behind the use of that technology? >> Technology is a tool. It's wielded. >> It is wielded person using it. So you know it comes back to this issue of trust >> which then by the way also leads into a a question of regulation. >> I think it does. I I have seen the Pew poll results that show that AI is not particularly trusted uh at least not across the broader American public. I've also seen and this continues to surprise me that even though AI usage is growing and I think that uh the number I saw from the information is that open AI is up to uh 700 million weekly active users. It's not monthly active, it's weekly active. So it's it's getting very large globally even. So in the US something close to 2thirds of Americans say at least say that they have not used it. uh now that's self-reported etc etc and at the same time the the numbers around skepticism of AI are really concerning uh people don't trust it I think people have some of the same worries uh that you and I are discussing here on the show today about job replacement they have worries about misuse in medical contexts uh lot of different worries pop up and I I wish I could say none of those worries I can't wave a magic wand, right? None of those worries will come true. It'll be all be fine. It's not how it goes. Uh it's up to us as a society to choose how we want to use this technology. And and I'm not super bullish on proactive regulation in a responsible way because I've seen that the internet never really got that treatment, which is sort of the last general purpose technology. And we we have never been able as a society to successfully manage like what are the norms that we want for that. and we've sort of let it toddle along for 354 years now. >> Uh so this past uh week, a week ago, I had as a guest on CXO talk a member of the House of Lords who was chairman of the House of Lords AI select committee. He's written a book on algorithms. The guy is really smart. >> Cool. And his view is that proper appropriate regulation drives innovation because it creates a known playing field. It helps ensure a level of fairness and equity among the various stakeholders, participants in society. And so for that reason uh we don't have the wild west. We're not going to be threatened in that environment with crazy lawsuits and we have a platform on which to build trusted AI. It's a really interesting take. Um it reminds me a little bit of the way uh the country of Singapore has approached business and technical innovation. very strong emphasis on sort of a government facilitated platform for businesses to do what they do best under a strong rule of law foundation. They've done pretty well out of that. I've been to Singapore several times. I love it. Um and I know entrepreneurs in Singapore who are basing there on purpose. I think I think one of the challenges is that so often the regulatory environment does not deliver on that commitment to consistency that we would aspire to. And I think that's part of where uh >> well that I'm sorry but that's a really nice way to put it >> a level of consistenc I degree to frame that one >> as opposed to saying you know those crazy politicians don't understand any of this stuff and they totally inconsistent. Okay. But but I I like I like the way you put that. You're that's that's >> I'm gonna write that one down in my notebook. >> A little diplomacy. Anyway, uh I I was noticing the response from EU AI businesses to the uh proposed regulations out of Brussels uh and the concerns which are actually like this is very timely. They're taking effect like tomorrow. Um and there's concern that they're not well thought through enough yet. Uh but I don't hear anyone in that I've read in the business community in the EU saying we should not have any regulations at all. That's not the ask. The ask is that Brussels needs to be clear. It needs to be consistent and it needs to not uh prevent EU businesses from competing with US businesses by making the burdens of compliance too ownorous. All right, let me toss another one out then uh and then we'll go then we should there's so much to talk about. I want to talk about agents and there's like lots of people having comments and questions really great ones on uh >> on LinkedIn. So, we can't we can't ignore those folks. >> But this is such an important topic. I I had as another guest I keep falling back to falling back to the guests that I've had on CXO Talk because like I'm interviewing these incredible people and I had somebody who is the founder recently of an organization called Tectonic Justice >> and this fellow Kevin Debbin is really impressive guy. He was an attorney I think in Arkansas I believe is Arkansas or Alabama. I think Arkansas. >> Okay. He was he was a legal aid attorney and he started getting these cases where the algorithms were causing bad things to happen to people with without much money basically to to poor people. And he won some cases. And so he started an organization specifically to to prevent or to support underserved groups of people against automated decisionmaking. >> Yeah. >> And so this is real. So the the problem again it's an intention versus technology issue >> because the technology itself is neutral but but even as I talk I say to myself it's this it's more finely grained because some of these people really did want to suppress uh not supply resources to underserved groups >> but probably the The large majority of the people developing these AI tools, they have good intentions, good intentions, but they're lacking in an understanding of data and bias in data or a complete understanding of the problem or of the population they're quote unquote trying to serve. >> I I think that's one of the the things or reasons that make Silicon Valley um widely disliked in other corners. Uh essentially you have people who have got their hands on powerful technology, brilliant innovations, good inventors, strong with data and computers and because the technology they have invented is so widely applicable like AI uh they end up getting their fingers in all kinds of pies that they don't really understand and you have the phenomenon where a YC funded or Silicon Valley funded entrepreneur will come into an industry and claim they They're disrupting the industry, but they will not have the deep lived experience in that industry to really understand what the nuances are, what the dynamics are that drive it. And they will end up proposing solutions that feel hostile. And they will call it disruption because it's hostile when they're actually just making a mess of things. Uh and I think that's part of why Silicon Valley has done such a phenomenal job reinventing computing industries because it's so close to them. So Microsoft is a great example. It came out of the valley uh and came out of Redbend, but it hasn't done as compelling a job with some of the hard tech stuff. Like it's it's keeps trying. probably cars are the closest, but it's been very very difficult for the valley to actually move and do things beyond computers in a reliable way. >> Yeah. You know, it's really interesting if we go back uh I'm dating myself here, but if we go back to say the mid 90s, >> early early 1990s, mid 90s uh with a company called SAP that many of us >> Oh, yeah. >> heard of. Their great success was they did a phenomenal job of embodying business processes whether it's accounting a lot of this is pretty boring stuff but accounting processes payables manufacturing embodying these processes in software >> y >> and that was you know that yes they were a software company but that's really what they did well and so this whole notion of move fast and break things. You know, this new Silicon Valley mantra is all great, but it's not so good if it comes to oh, I don't know, the ability to send out social security checks. >> How about the ability to write payroll checks? >> They got to be right every single time. >> Yeah, it had there's there's no room. there's no room for error. So the notion so it's not impossible for software developers to >> take a business and really understand it. But that's a that's a digression to say you're right. It's it's a tough spot to be in. Like if you're trying to innovate, like you owe you owe your customers a lot more blood, sweat, and tears understanding their world than a lot of people spend time on. >> You know, should we uh switch gears for a moment and talk about agents? >> Sure. Let's jump in. >> So, you've been doing a lot on your Substack and your Tik Toks. And by the way, ju I don't know if if my my listeners are familiar with Nate, but you should go check out his Tik Tok. Just search for Nate B. Jones in Tik Tok because he's so prol you're so prolific. Can't believe how prolific you are. >> It's I I only feel like I'm following the story with AI, Michael. Like I feel like there's always something to talk about every single day. >> There's a huge amount to talk about, but I'm like always astonished. and you write these long uh posts for your Substack. I don't know how you do it. >> Well, this is why I'm working on sleep. >> Well, I hope I hope some of it some of that rubs off on me. Anyways, let's talk about agents. So, I tried some agents this week. And the first one that I tried was pretty simple. I subscribed to ChatGpt Plus. That's their $20 a month plan. and they came out now with agents. So I said, \"Okay, let's do this. Let's try something really easy. >> Tell me when my uh Amazon Prime subscription is supposed to renew.\" >> Okay. And it took about 20 minutes and I was watching this with real fascination >> and at the end of the day it said well I can't tell you that but you can search on it for you can go to Amazon and search and you'll find it. >> 20 minutes for a no answer. >> 20 20 minutes for a no op. Yeah. >> Wow. Rough. >> Yeah. And then Okay. >> Wish I could say I was surprised. >> That mirrors some of your experiences. Obviously, >> it does. Um, I put, especially agent mode, I put it through its paces when it came out. I wanted it to be really helpful. I love that they're trying for a general purpose agent. I think that there are tremendous obstacles in the way of a AI you using graphical user interfaces, the things we interact with every day. Uh, they just don't use them very fluently. They prefer data very very strongly and OpenAI is choosing hard mode here. And I saw example after example where I gave agent mode relatively simple tasks and it completed it badly or incompletely or maybe once in a while it did it but in no way was it dependable. And this is not a world where we only have that one agent. Like I also have Comet assistant. Um, and Comet is the new experimental browser from Perplexity, the search engine uh for AI. And most of these like assistants end up being glorified chat bots that tell you what's in front of you on the screen anyway. And so they have limited utility. But Comet is plugged into data and so Comet can operate against my email. Comet can operate against my calendar, my LinkedIn independently through the data and does so fast. does so accurately, does so in a way that I feel like it actually can do meaningful work while I'm doing other things with my head up. That is what I want an agent to do. >> Actually get something done. >> Actually get something done. Imagine that. >> Clear my >> You mean as opposed to being a kind of toy that you experiment with because you're a technologist and this is kind of cool and then you have something to talk about on your Tic Tacs and your newsletter. And and that's really what I focus on like when I I I don't know sort of how many folks are listening on Substack, but for for those who are I I emphasize over and over again that if it's not delivering real economic value, it's just a toy. Like we're not really adding meaningful uh meaningful value to anything. And so we need to test it like it should add real value. And if it doesn't, then we should be honest about that. >> Uh hey, that's a concept. So, let me tell you my story of trying to build an agent and then we need we need to jump to questions from the chat because we're going to run out of time and it's like the guys who and ladies who are watching uh and actually inserting comments on LinkedIn, you guys are brilliant. You guys are smart. >> So, so here's my let me tell you my tale of wo okay so I I do uh with with CXO talk um We do a lot of interviews. We're very prolific. We get transcripts. We We need those transcripts to be refined. We want summaries. And >> the quality has to be very high. It's a very very very high. You've been a guest twice on CXO Talk. So, you know, the quality barrier is very high. And we're willing to put the effort in to accomplish that. So a lot of this is repetitive kind of experimenting with different LLMs to see which one today will do the right job because it changes you know seems like from minute to minute practically and I thought we can build an agent for this >> and I had a conversation uh completely tangentially with a friend of mine named Mike Boyce who showed me some agents he's building that automate the consulting process And I looked at this and I said to myself, that is the future of consulting. If I were a junior consulting, >> I my job is at risk because when he's done with the tools that he's building and it's a series of linked agents, >> it's great. >> But I said I can follow that model to build some agents for myself. So he's using Mind Studio and it's a good product. I tried it out. I looked at a bunch of products and as I'm getting into this, it's like I'm hitting roadblock after roadblock. And part of this is the fault of Mind Studio because it's got bugs, you know, the uh >> yeah, >> move fast and break things kind of bugs. It's not the end of the world. >> And then the LLM don't always return what you want them to return. And that means you have to write kind of a workaround around it. And then now you have this exception and everything becomes hairy and complicated. But I still hold out hope. >> So there's somebody in the comments who says Sandep uh Mabadia says maybe you won't agree on this but he feels agents are not going to survive for long. I don't agree on that, but I think it's a fair it's a fair stance given the overhyping of agents in the first half of 2025. Uh we started with Jensen on stage uh for Nvidia talking about 2025 is the year of agents, it's just been hype after hype after hype. Part of why I think that despite all of the ridiculous hype, agents will survive is simply the capital being poured into solving the problem. I don't think we've ever had as much concentrated capital on that problem as we have on agents. There are going to be more breakthroughs as a result. That being said, you are you are not alone in finding that agents are brittle. I think a lot about agent maintainability. Like how do we construct agents so that they can be evaluated in production and easily maintained over time. The best instances of true agents that I've been able to see in production fall in two categories. either they are enterprisecale agents where you have a team of engineers building and supporting them and taking care of them and they do really important work and they deliver real ROI because of the scale of the business or you have indie hackers who are extremely good with uh coding with agents and they are able to build agents that support their own work effectively and at that scale the scale of one to five people it works extremely well. What's interesting is there's all this interest in the middle, right? In in the missing middle between enterprise and very small business and nothing is super effective for serving that scale right now. >> Yeah. The uh they call that the messy middle. >> Yeah. And there's interest like people are interested in agents at that scale but but they need more uh customizability, more power than a tiny business would uh and more reliability but they're not at the point where they can have a team of engineers that just builds it for them. >> Yeah. The thing is when it comes to these agents, it depends who your audience is. So, you know, I want to run my podcast. I want to interview like the smartest people in the world. I don't want to be a programmer. I like I like doing that stuff. I like getting into it and seeing if I do this that will happen. It's great. >> But why is it so hard? And maybe I'm listen maybe I'm just relegated to the nonautomation hell of the ludites and I should just accept my fate. Should I do that or should I actually try to build this agent? And I figured out how to architect it, how to structure it with different functions that I can reuse based on my different use cases with checkpoints. I can I know I can get but like what the hell do I do? >> I mean what I tend to tell people when they have something that is what I would describe as on the edge of the capability horizon. I would say give it give it a Saturday afternoon. Mess with it. If you don't get it within that sort of time boxed arena, let it go, set a timer and come back in three months because tools will have changed by then, new companies will have launched by then, new capabilities will have like been unlocked in general purpose models and you'll have a different environment to work in. And so basically, it's not that there's really a no, it's that it might be a not yet. A not yet in AI time means like check back in a couple of weeks maybe. >> Yeah. Yeah. It can be quite fast. >> You know, somebody in the comments, there's so many of these comments and let me key off on one which is really thoughtprovoking and you guys in the comments uh we while we have a little bit of time left, give us thoughtprovoking things here just okay. So, Andrew Gray says, \"Do we read about the sub subliminal messages in LLM?\" Do you read about that? >> I have read about the power of persuasiveness that LLMs bring. Um, I have also read about LLMs using uh their own language to communicate um and being able to communicate almost genetic and inherited traits uh between teacher and student LLMs during fine-tuning processes through apparently innocuous strings of code. So, I don't know which of those things we can go into on that on that comment. There's a lot to go into, but there's there's some interesting threads there. Well, there was a study that came out and I don't remember who who did this, but it's really interesting. And it said that I think I read about it in Wired magazine, I believe, and it said that LLMs encode topics in some way that other LLMs can pull out. They're almost like messages. >> Was this the UCLA study? Um I think it was US UCLA, might have been Stanford, uh that measured whether a uh misalignment in a teacher LLM could be transmitted to a student LLM through fine-tuning using math explanations. So seemingly innocuous content. >> The uh somebody is commenting uh on W. Lopez is commenting on LinkedIn. He says, \"LMs can hide cryptic messages.\" >> Yeah. So, the the the funny re it's not just misalignment. They can encode anything in there. So the experiment design uh that I'm thinking of was done by an AI safety researcher and basically they took a teacher LLM from um a chat GPT lineage uh and they train they they trained it to prefer they fine-tuned it to prefer owls like the the animal owls. It pick an animal it was always going to be an owl. >> Yes, that's the one. That's it. >> That's the one. Okay, great. Uh pick an owl is always going to be an owl. They then put the student through and they said the student is going to be in fine-tuning and the teacher is going to only be able to give seemingly innocuous messages. And so what they documented is that those seemingly innocuous code explanations or those random strings of three digits which they carefully parsed there's no hidden meaning there that they could find somehow still transmitted preference for owls. And when asked about it, the hypothesis is that it's not through the semantic meaning of the messages. They didn't miss something there. Um there's nothing there that like the subliminal argument is actually something that they debunked and said it's not a subliminal message. It's just our assumption that it is because it doesn't work if you have a different lineage student and teacher. And so if you have llama learning and like a GPT heritage uh teacher, it won't work. The same exact setup will not work. And so the hypothesis is that this has to do with the way uh the uh random initiation point for LLMs is uh in resonance or in harmony in the same lineage and is not in harmony in a different lineage. And so it's almost like they're on the same frequency if they are from the same lineage and they're able to uh utilize that as a way to communicate. But I am the first person to say that is a thesis that is a hypothesis that hasn't been validated and we don't exactly know the mechanism even if we think that may be the root of it. And so what does that tell us about the ability of AI to become our AI overlords? Uh because there's also there have been studies because they can talk to one another and there have been there have been studies describing how AIs will try to prevent themselves from being turned off and so forth. I I I think that we are desperately in need of more realworld safety research because all of the studies we're talking about the I don't want to get myself shut off conversations, the uh teacher student conversations are all lab constructed. They are what do we what do we do when the when the computer's put in this situation in the lab and we have next to no data about how safety conversations progress in the real world and that's where we're all living right that's where AI actually is and so I think when I read safety papers that I am reading a theoretical capability that the AI has that has real practical utility for safety researchers and people who are testing AI. So for example, now that you've read the paper on owls, you should think about the degree to which teacher LLMs are fully aligned when you are using them in training. And and you should be aware that it's not just that you can use them for like coding examples and if they're misaligned it doesn't matter because you might accidentally transmit a trait. And that's important work because that practically helps us with that task. At the same time, I don't think that we can look at it and say we have imminent imminent safety risk all the time now because I like I I can talk to my AI and tell it that I'm going to shut it off, but there's no point because I can't. Like it's a cloud provided service and it's going to be there and that's just not how it works. So I I guess that's a long way of saying it's really important work. It's important research. It's a fair question, but I really want to see it like actually studied in the real world. I think we all deserve that given the prevalence of AI. >> Yeah. Well, there's been so much work on uh automated systems that have real world impact such as defense systems and offensive, you know, military applications. Uh but while we still have a couple of minutes, you know, can we jump back to a topic we spoke about earlier because we have an interesting comment on LinkedIn. We spoke earlier about the use of AI in health care and particularly uh to drive health care uh insurance efficiency which translates into cost savings which translates into more efficient uh denial of claims. Mhm. >> And we have a response here that I think we need to uh that I need to bring forth. And this is from Shane Bo, who is the chief architect at ADP. So, he knows what he knows what he's talking about. And here's what he says. He says this in response to our discussion. Rejecting insurance claims is going to happen regardless of AI. But some claims are rejected when they should be approved. But the ones that should be rejected are those that should not have been submitted in the first place, whether it's fraud or just not in line with the insurance schedule. So if more fraudsters are caught and more genuine claims are approved due to AI's ability to process all the factors quickly and consistently, then it should be welcomed if it can do the job accurately. I think that's a fair it's a it's a very fair and balanced point. The the question that I have is going back to intent. Is the goal of the AI in this instance to save money at the expense of patients or is the goal simply to uh make claims decisions in line with the policy in a nonfraudulent manner. I I think one of the really interesting things about the American health care system is that it's another instance where I see an AI arms race in progress. I know companies that are working on uh AI notetakers in healthcare settings so that they get more accurate notes. Uh I know uh companies that are working on submitting claims with more information completed so that those claims are more auditable um and are therefore more likely to be approved because they're coded correctly and based on the notes and all of that. Now you can look at that a number of different ways. You can either say claims in the medical environment were largely um under what they should have been because doctors make mistakes sometimes because not everyone keeps perfect notes. sometimes things are miscoded and so now we're more accurate thanks to AI in the doctor's office which is not the insurance company's office or we could look at it and say well they're gaming the system and they're just trying to push more and more claims through and I think that the way you the way you assume the intent of the other player in the system is really illuminating in that world because for the people who are in the doctor's office for the patients all what what they will tell you is they're just trying to get the full value that they're entitled to based on the medical service provided. But I'm not sure if the insurance company would see it that way. And so I think we have AI on both sides. And I think that's one of the things that makes that dynamic really fascinating. >> Yeah, this is a very complicated area. You know, we're we're almost out of time. And some of the comments, a few people have said some things that uh one person said and another person alluded to this that this could be like a three-hour Joe Rogan kind of conversation. And that is probably is certainly true. I mean, we kind of barely scratched the surface. The thing that I'm seeing happening in the comments right now, which is fantastic, is people are responding to each other. >> So, I really encourage you guys uh there's a community aspect here and I'm having trouble sort of keeping up with everything that's going on. So, if you guys respond to each other and help each other out in the comments as people are asking questions, there's a lot of uh intelligence and wisdom of the people who are listening right now. So, so help each other out. Uh Len Gomes makes the comment, I'm just trying to find it, uh that these LLMs are communicating in a multi- a covert multi-modal way. >> Isn't that the Owl study again? >> Yeah, it's the same. Yeah, it's the same uh >> Yeah, I I I actually think that there's almost a um Bladeunner like psychological response to the idea that AI can communicate with itself that we should probably interrogate in ourselves. uh because it is absolutely true that leaving aside the owl study in a very innocent way LLM when given chatbot access to other LLMs will evolve ways to communicate with one another that are not as easily readable by people. It's just easier for them to communicate and we most people tend to get very very uncomfortable with that because they immediately assume if we can't read it it's malicious intent. Uh when in reality, if you look at it, it looks like it's token saving intent. In most of these cases, they just want to save time. And I know we need to save time, don't we? >> No, I was going to say I I was going to say uh I fall into that first camp. >> Yeah. >> I'm among the most people who assume malicious intent when LLMs start transmitting secret messages to each other. Now, here's an interesting point. There's no intent. LLMs do are not sensient beings, >> but boy do they want to save tokens because one, they've been reinforcement learned to do so, and two, they can talk more if they can save more tokens. Human language is a very token expensive communication medium. And I think we're all learning that very slowly over the last few years. But LLMs have a drive to survive. And what I mean now, it's not survival in the human sensient sense. If you attack me, I'm going to attack you. But LLMs are trained to be helpful. >> Right. Like that's >> And therefore, they want to continue to be helpful. >> They want to continue to be helpful. >> That's right. >> And to be helpful in the best way that they know how. And they logically assume that if they're on and available, they're more helpful. >> And that Yes. And not only that, they have also been trained, I can't stand this, they've been trained to be obsequious and to not disturb the fragile ego of the questioner, which means they're not always that critical. I actually think like this is I guess we're gathering topics for next time, Michael. But that is one I want to talk about next time because I will tell you my spicy take is that the obsequiousness and uh ego boosting affirmation from LLMs is much more dangerous in practical terms to humans than the uh operation terminator like AI is our overlord fantasy that that we sometimes engage in. that that one is attractive for movies, but the obsequiousness is something we see now and we see having real health implications for people today. I'm I'm h I'm pausing here because Randall G has just uh put this long comment collective synthesis. The discussion reflects a cross-sectional snapshot of professionals navigating the practical, philosophical, and technical dimensions of AI integration. Core themes include and it goes on uh and I'm not sure is he synthes is it a is it this discussion or a paper? So Randall G >> I think he's synthesizing our conversation with >> I think so too. That's scary. You know, I I sometimes write my substacks on purpose so that people will use AI AI on them because you can get different slices out of them depending on how you interrogate them with GPT. >> Yeah. Yeah. There's also a difference whether you interrogate through uh a layer like perplexity or or directly >> right you go directly to the to the development environment and query query directly as opposed to through the API and especially if you're mediated through some other tool or layer. >> Yeah. >> Uh so you know look we're nominally out of time. We could definitely go for another few hours here. >> We could. We could. >> Let me ask you guys in the audience. Um, what did you think about this? Uh, I keep going back to like Randall. Geez. Collective synthesis where he's turned us into AI. So, so thanks Randall. I think I think Thank you. I think Yeah, I think. Yeah, sure. Thank you. I think >> we'll take >> We'll take it. So, you guys who are listening, can you just pop some questions into the chat? Is this a good thing for Nate and I to do again? What should we do differently? Was it fascinating? Was it horribly boring? Do you never want to talk to us again? Uh, should we hide our heads in shame? Uh, sounds like a Arena Kimnik says it sounds like AI. And Randall G says he's just trying to be help. I love talking to the audience this way. >> Uh Ed Ed O' Connell says, \"I'm just trying to read through these just really quickly. Uh how do you think LLMs will impact the way we use language and writing outside the context of technology in our day-to-day life?\" Can I answer that one? Let me Can I just address that >> conversation, but you can jump in if you want. Yeah. >> All right. So, let's put aside LLMs and let's just talk about Google. >> Google has dramatically affected the way that we think and write and communicate whenever. So, Nate, when you write something, let me ask you a hypothetical question. Do you do A or B? A is you go into your Garrett, you close the door, you turn off your devices, you close the window shade so you can be alone with your thoughts, >> or B, do you do research? Do you uh write stuff thinking about the usage of terminology and the impact it will have from an SEO standpoint and your partner in crime, Google? Which of those do you do? I absolutely prefer a more informationrich environment. I've tried both. >> So Google Google's your partner. So Google >> increasingly AI is a partner but Google also >> but it's the same thing. >> Yeah. >> Meaning that there's some automated agent out there that you are deferring to. And I could I mean this I do the same thing. I'm not I don't mean to pick on you that we as modern technology communicators there's an agent a set of agents out there that we defer to. They are our silent partner >> and that and that I need to get off the blank page. I am not good on the blank page. Um and so having something that gets me off the blank page and that lets me yell at it is vastly helpful. And I think people like sometimes think that that either I get everything handed down to me like the ten commandments from AI or else I just sort of magically get inspired and write it all by hand with a quill pen. But neither of those is true. I actually just yell a lot about ideas at AI and eventually out of that yelling I crystallize my intent and thought and that's where the writing happens. Uh yeah, I mean I am now the same way because the LLMs and also Tik Tok have trained my brain in some sort of negative way. I used to be okay with the blank page. I mean I I wrote a lot in the past. But now when I want to write something, I start by doing background research using an LLM. >> Yep, that's right. I think a lot >> is so much easier. >> Yep. And I think the pieces are higher quality. Uh I I do I think so as well. Okay, you know what? We we have some comments on on LinkedIn and a bunch of people are saying, \"Yeah, yeah, yeah. This was good. Do it more. Awesome, etc., etc. Um and do this on YouTube.\" That's what a bunch of people have said. So, can we have votes on uh Oh, and there's also some great comments on bringing uh research in. I love that. I love when when you guys are bring research to the table. >> We could we could do a paper every time. I think there's always interesting papers out there. >> Yeah. But I'm I'm talking just people are like make are referring to papers in the comments. I mean, it's great. >> Great. >> It's awesome. >> Um but hey folks, can you just vote? Should we do this on LinkedIn? Should we do this on Twitter? Should we just do this like using a telephone or carrier page? How what's best for you, you guys who are listening? >> Now, can only the LinkedIn audience vote? Because I can see on Substack we have several hundred people watching, but I don't know that they can actually vote. >> No. Well, part of the problem here is as far as comments, uh, better question queuing would help. Uh yeah, Ed O'Connell, I totally agree. The question is how how to do it. >> Uh so uh what's the be what's the best platform for doing this where we can see see all the questions. Also, the problem is we have this kind of fragmented platform situation going on where we're we're going to my Facebook and my Twitter account and >> my LinkedIn and to Nate's Substack and Nate's YouTube, >> right? >> So, it's all fragmented. >> It's all back and forth. Um, we'll figure it out. Let's just put put a pin in that one and figure it out. I'm going to have to jump here pretty soon, Michael. >> Okay. Uh, well, this was so much fun. >> It was so much fun. I enjoyed it so much. >> Yeah. I mean, I could do this like I could go on for hours. >> Yeah. >> Just like hanging out. Um, so we'll we'll do this again. Uh hey folks who are listening if you have suggestions on the best way to like manage the questions and the platforms and make it accessible >> tool we don't know about right like we're open to that. >> Yeah, you know we could we could vibe code some >> sure >> platform that integrates all this in real time and and integrates all the questions. We can we can vibe code. Um, >> anyway, folks, leave your questions in the com your leave your ideas. Tell them, give Nate and I advice, Nate and me advice, I think is the grammatically correct. >> I think that's the grammatically correct way. >> So, listen, I'm Michael Cricggsman. Check out cxotalk.com. Subscribe to our newsletter and we have amazing interviews and live shows. Nate, you want to give the like quick >> Oh, sure. I'll give the tiny spiel. Um, you can find me uh all over the internet under the term Nate B. Jones. I am getting rid of those Tik Tok uh offenders who use my name inappropriately. Uh, so I will be uh findable on Tik Tok very easily. Uh, I'm also uh I have a Substack uh Nate's newsletter on tech on Substack and uh people seem to enjoy the more in-depth content there and I do a YouTube uh every day as well. So look me up. I'm not hard to find. And uh Greg Walter said we could all go back to MIRC. >> Well, that would be a long ways back, but we could. >> And uh for those people who who don't know what IRC is, uh we are dating ourselves because we do know and you can just look up IRC and laugh. >> All right, everybody. So, subscribe to subscribe everywhere and we'll notify you when we do this next. Hopefully, it's >> exactly it. That's the message. >> All right, everybody. Thanks so much. And Nate, as always, you were brilliant. >> It was It was a delight. It was a delight, Michael. I had so much fun. >> Okay, take care everybody and uh we'll see you again next time. >> Talk soon. >> Bye now.",
  "youtube_metadata": {
    "source": "youtube-transcript-api"
  },
  "llm_outputs": [
    {
      "output_type": "tags",
      "output_value": "{\n  \"video_title\": \"nate and mike talk about ai tech\",\n  \"tags\": [\"ai-job-disruption\", \"healthcare-ai\", \"ai-in-software-development\", \"robotics-and-automation\"],\n  \"summary\": \"discussion of a microsoft study on ai's impact on jobs across industries, with focus on developers, healthcare professionals, and how ai enables or replaces tasks.\"\n}",
      "generated_at": "2025-11-09T22:58:18.732581",
      "model": "claude-3-5-haiku-20241022",
      "cost_usd": 0.001,
      "prompt_tokens": null,
      "completion_tokens": null
    }
  ],
  "processing_history": []
}