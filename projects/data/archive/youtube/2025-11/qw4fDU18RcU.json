{
  "video_id": "qw4fDU18RcU",
  "url": "https://www.youtube.com/watch?v=qw4fDU18RcU",
  "fetched_at": "2025-11-13T08:20:13.833549",
  "source": "youtube-transcript-api",
  "import_metadata": {
    "source_type": "single_import",
    "imported_at": "2025-11-13T08:20:13.833509",
    "import_method": "cli",
    "channel_context": {
      "channel_id": null,
      "channel_name": null,
      "is_bulk_import": false
    },
    "recommendation_weight": 1.0
  },
  "raw_transcript": "I have a confession to make. I bifocated again. And I know what you're thinking. Felix, did you split your PCIe lane so you can fit two GPUs again? Yes. But so what? Because what I didn't say in my last video. When I got the BIOS from the random stranger online so I could buy fur cake, what I didn't say was all the lanes were bifurcatable. I can bifurcate as many times as I want. It's legal. I bifurcated again. Nine GPUs for mortal men doomed to die. >> Just one more. One more. >> 10 GPUs. So, what am I going to do with all this space? I can fit my whole foot in there. What am I going to do? A foot holder? I had to do it. I had to do I had to I had to do it, man. Surely you will understand. Now, I know what you're thinking again. Felix, what are you going to do with all of that? Six dimensions. I am going to play Minecraft in six dimensions. I realized that I have a tendency and maybe you can relate to this as well of setting a goal without any regard for is this a good idea? Do I really want to do this? What is the point of doing this? I just really wanted to max out my computer and that became like a weird obsession. But here I am and I finished my computer because I know what you're thinking. Felix, did you add a 4090? Those run on 475 watts. Are you crazy? You can't do that. You don't have that kind of power consumption. I can b Sorry. I can undervolt it, you stupid [\u00a0__\u00a0] The performance is negligible the last couple percentages. It's fine. Now that we got all that out of the way, what have I actually been doing with this computer? I've been doing protein folding simulations. That's right. I knew I could rent out my computing power and make money that way, but that's for shablo. Protein folding simulation is where it's at. Basically, scientists needs to run these protein simulations for their studies. It helps them better understand different diseases, but it takes a lot of computing power. So, you or me can help doing that and spreading that out. So basically having like a mini data center, it can actually make a big uh a big help. So I've been running that overnight whenever I can and it's been really fun to climb the leaderboards. That's really all I care about. Charity leaderboards, we're going obviously I'm just joking. But it sound, first of all, I get it. It sounds like a scam. It sounds like I'm patting myself on the back while someone is getting rich off crypto. That's not the case. I've looked into this. It is 100% legit and it's been around for a very long time. I just never heard about it for some reason. It seems like maybe you think they're paying me or something, but I genuinely just think this is very cool. And get the best part. I've made a team so you guys can join in. You don't need a beast computer to do this. And if anything, it really shows how a lot of people come together. You can make a big difference. And it's a very cool flex to say that your computer have supported cancer research or Alzheimer's and other diseases. So, please consider joining the team team per and get this, the team number that was randomly generated. You're never going to guess it, okay? 10 66 966. God gave us that number. God gave us that number. Grab your CPU and GPU and let's fold protein together. If you have some time later today, spend 30 minutes and set it up. I've been aiming for top 01%. Let's get folding. >> Me and Marcia have been planning to go to Sweden next month. And there's so much involved with tickets and where to stay and then it's a 12-hour flight back to Sweden even though it's direct now, which is amazing. But the worst part is trying to find out how do I get internet. You cannot travel abroad without internet. That's a terrible idea. I've done it. Don't do it. And I always dreaded it because signing up to rent the Wi-Fi after a long flight is the least thing you want to do. Having to worry about when you land, okay, where can I buy an e sim or where can I buy an actual sim is a terrible solution. Luckily, there is s is one of the most budget friendly options for an electronic sim. I use it every time I travel and it's genuinely the best product ever. They should be paying me. Oh, wait. They are paying me. I'm just kidding. I've already signed up. I put in how much data I need. I will just land and it will just work. I don't have to think about it anymore. And that's how it should be because there's so much to think about when you're traveling. So I love SY. It removes a huge piece of stress when I'm traveling. And I met a lot of you guys here in Japan that said, \"Oh, I use SY when I traveled here.\" And it worked really well. So certifiably works well in Japan. They keep increasing countries, but there's already a ton to pick from. As an online privacy respecting individual, since this is under the Nord company, they have all these privacy respecting features built in, which I appreciate because I don't really trust all these random eim brands showing up. You know what I mean? They have 100% refund. So, try it out. And in the checkout, make sure you enter PewDiePie because then you get 15% off. It's so fun to me just watching money disappear. So, take advantage of that deal. That's PewDiePie at checkout. So yeah, download it now and have it ready for your next trip. Thank you, Sailor, for being an amazing product and an amazing sponsor that I can proudly stand behind. Scan the QR code on the screen right now and enter the code PewDiePie for 15% off. Another thing I wanted to do with this computer was to run AI. If you have this many GPUs, you at least got to try running AI on it. And I'm not going to lie, it became my next big I have to max out. What's the biggest model of AI that I can run on this computer? That's what I wanted to find out. And it turns out it's complicated. You know, this computer costs 20,000 roughly in terms of running AI, that's relatively cheap. That's what I was trying to say because the cost for uh for running AI is just like I can't it goes from here to No, I can't make that joke. The cost for running AI is just bonkers. is stupid. Okay, so what AI did I run? First, we have to make some things crystal clear. I do not f with image generation or video generation. I don't really have that strong of opinion about it, but all the drawing nerds supported me in my drawing video, so I stand by the drawing nerds as a fellow drawing nerd myself. I genuinely think AI art looks ass. It looks bad. You can tell immediately it's AI generated. And the art that does look cool has been straight up ripped off from another artist. So why not just look up the artist? I don't get it. I can see it being used for the lowest stock image or piece of a background or something, but more than that, I just think it's lame. Second of all, I do feel like I'm in a weird place with this because I'm going to yap about AI here, and I hate people yapping about AI. I genuinely can't stand it. Seeing AI everywhere is so irritating to me. I went to a hotel last month and they were like, \"We have AI generation integrated in the hotel room.\" I'm like, \"Great, stop.\" Even here on YouTube, the AI features are so useless. It's just become the hot next buzzword and it's very annoying. But on the other hand, the people that just hate AI are equally centrist take. I mean, they're all bad. And I'm I'm just kidding. But it's like I don't know if you heard Markiplier got cancelled because he used AI. Please don't please don't cancel me. Please. If anyone watches Markiplier, click away the video right now. It's not going to be good. No. But from trying to self-host AI, I realize just how much misinformation there is about AI, especially with cuz I didn't know anything about it. So, without further ado, what model can I run on this thing? Well, I asked AI itself. I went straight to the source. I was like, \"What model can I run?\" It goes, \"Bro, I got you Llama 70B.\" And I was like, \"Cool. It runs. It's not bad, but I didn't really go like I want to go, you know, I want to feel like, wo, look at the beast computer, Beast AI.\" I didn't get that opinion. If anything, I was like, I that was surprisingly easy. I I think I can run this on four GPUs. Actually, lo and behold, it runs on four GPUs. I have not maxed out at all. What am I going to do? Have them talk to each other? Then I get it running on two GPUs. What am I going to do with that? I give them a little tea party. No, I want to boom. I want to max out. Can a guy max out? It's the fattest stack of AI I can slap on this thing cuz it ain't 70, I tell you. So, I math the math. I was like 120 billion. For those of you who don't know, every model comes in uh different sizes. Bigger model generally means better, but not at all a rule. Don't listen to that. But I knew the biggest model I can run was 120 billion parameters. 120B doesn't exist. Nothing. Nada. And I know what you're thinking, Felix, there is. Yes, because as I was complaining about it, Open AI chat finally lived to their name and released an open- source model like everyone else has already done. And guess what? 120 billion parameters. I couldn't believe it. The timing was just insane. And I ran it and I was like, I I did the thing. I I was like, it feels exactly like Chad GPT, but it's fast as it's so fast. I can't read that fast. Can you read that fast? It's crazy. So, I was like, I did it. I maxed out, but I think I can get it running on four GPUs. You see, to deploy AI, I use VLM. You can do different things. I use VLM, which means I have to stare at the VLM loading screen. Running AI, everyone's hardware is going to be different. and differently optimized. So, you need to have like a little cookbook that you set of different parameters before you fire off that thing. And it takes a while for it to load up. And I've been staring at that loading for too long. I swear I understand what the incomprehensible reading text means without being able to read it. That will never run. But then when it does run, it's like I go, \"Sorry, I need to stop doing that.\" But I realized I could probably run this uh model on four GPUs. Lo and behold, Chad OS runs on four GPUs. I'm like, I should be happy, right? But I'm not because I want to max out. Can a guy just max out? Is that too much to ask? So, if you math the math, I should be able to run a 240 billion parameter model. I should, and you know what? There is, Gwen, 245B. But there's two problems. Number one, I tried it and it never [\u00a0__\u00a0] runs. Number two, even if I do get it running, I don't have enough memory to actually use it. I could maybe fart at it at best and it would die instantly. Maybe a little squeak back. I don't know if I'm lucky. But I thought, hell, for the sake of the memes, let's max out and get this thing running. And finally, it runs. Oh. Oh, let's go. I couldn't believe it. I was like, \"Yes, I did it. Finally.\" I had to set this thing so it spreads out equally. I don't know if you knew that. So, now you know that. To me, this felt like a huge win. But I decided to keep trying. I was like, \"Okay, maybe I can load it with more tokens.\" So, I double it and it runs. I was like, \"Okay, nice. Now, I can maybe sneeze at it. Maybe I could even do a little wave.\" Like, it's not practical is what I'm saying. But, I double it again and it loads. I double it. It goes to 16,000, 32,000, 64,000. I get to 100,000 tokens on this [\u00a0__\u00a0] which is practically a book. Like, amazing. I can actually run and use this model. 235 million. Yeah, Chinese AI strikes again. This should not be possible. I remember I was troubleshooting this with another AI and it kept going, \"Stop. It's not going to work. Stop.\" And I'm like, \"Shut up. We're testing it out.\" Basically, it was just an optimized quant if you must know. So, thank you. Okay. But then another plot twist. As soon as I ran this model, that's when I realized I wish I never run this model. Too much power. I'm not even joking. I've been learning how to program as part of my tech journey. And then I saw this thing programmed locally offline on my computer. My soul just left my body. I was like, well, there goes that ambition. I'm just kidding, by the way. I I still think it's an amazing uh skill to learn and I I've been enjoying it so much because it's like it takes up so much focus of your brain. But I also find it really cool to see your own computer write code for you. When you host AI on your own, it's not going to be able to do anything. It doesn't have search. It doesn't have memory. It doesn't have any functions whatsoever. You can just talk to it. So I started giving it all these features, but I made itself give those features. So, I was like, \"Matsia, check this out. Matzia, the machine is making the machine.\" I don't know. I just thought it was really cool. Okay, welcome to my tutorial. No one has so far made it through the entire demo. So, a true testimony to your attention span. This is like the meme of like, \"My buddy's going to show you this. You have to pretend you like it. PewDiePie's going to show his web UI. You have to pretend you like it.\" First of all, it has toggle sidebar. Check this out. It toggles. And look, toggles here, too. Uh, now if I want to talk to AI, I go, \"Hi.\" It's really [\u00a0__\u00a0] fast. Like, damn. 216 tokens per second. It has audio as well. >> Sure. Here's a joke for you. Why don't scientists trust atoms? Because they make things up. Haha. So, I started adding more features to the AI just to test it out and because there are other options that you can uh self-host that are really good, but it was easier and quicker to just do it myself because it was so capable and it looked more epic hackery because it matched my aesthetic on my computer. But then I started adding, you know, all these things like search and memory and rag and I was like, damn, this is getting good. You can site your search in this and these are all privacy respecting and have free options which I think is really really important. If you ask this AI it calls me Felix Shurika often abbreviated as Felix show. It just makes up a bunch of information but you give it search and it's really accurate. I got really into building this web UI. I would love to share it for other people to use it because I want the principle of it to be private and being capable of running for free. A lot of times with self-hosting, they just want you to put API on everything. It drives me insane. If I have to watch one more YouTube video of an AI dude, bro, going, \"Hey, just Okay, guys. I'm just going to waste your time giving a bunch of outdated information and then we're going to put your API here and then another API here. You can't just API your way out of everything. How about you solve some problems for yourself?\" So, instead, I stole some code from a Chinese laboratory and now my AI has deep research. It's okay to steal from China cuz China steal from you. The way research works is that it keeps expanding its knowledge based on what it finds. So it does goes through different rounds and analyzes what it got and based on that it either keeps exploring different forks. Uh which I think is really cool. I was really proud of it. But I wish I added more feedback of what is going on while it searches cuz it's kind of boring to look at. I can set how long I want it to search as well, which I think I think is really cool. I could demo my web UI all day. I gave it so many cool things. I can summarize YouTube videos just like YouTube can, except it's actually useful. But the biggest reason why you should self-host AI, you put your lip to the camera and go and go. The biggest reason is because of memory. AI has memory, right? You probably noticed it if you use chat. It remembers stuff about you. And a lot of times when I used it in the past, it catches me off guard. I'm like, \"Wait a minute. How do you know that?\" Oh, I told you that. That's right. That's right. Okay. Well, I still don't want you to know that. Delete. Delete. And I heard friends talk about this, too. Like, uh, yeah, I use incognito mode or, uh, I'm careful with what I share with AI because I don't want them to know all this stuff. I delete all the chats to make sure it's gone. Do you think deleting the chat deletes the chat? Were you under the impression? Oh, I'm sorry. you were under the impression, no, go to this link right now. That's where you have to go to delete your data. I discovered this by mistake because I was trying to just cancel my subscription cuz I didn't need it anymore. But I was like, \"Oh, so they collect your data and train on your data even if you deleted it.\" Oh, yeah, that makes sense, I guess. And that's the whole point with my deing video. I I really fell down these two rabbit holes of of online privacy, ironically, I know, and self-hosting AI in the middle. It just makes sense. Here's the best example I can make because I had taken all the Google information that they had on me and I had given it to my own AI with the rag capabilities which is fast retrieval of data locally on your computer. Sounds super boring but it's actually really really cool. And I had forgotten I had given it to it. So I was testing out random queries and I was like who am I? And it goes oh you're Felix Shelberg. Oh you're PewDiePie. This is your address and here's your phone number. up like ah I mentioned rag earlier so I can ask who is my and we will have to blur that but it shows her phone number and it did it in 0.37 seconds again it was like oh I told it that and it's my data on my computer it's okay it's okay but I think that's the point like there's something weird about AI knowing stuff about you even though Google has been doing the exact same thing forever ever. Just when you hear it back from AI, you're like, \"Oh, this is weird. I don't like this. This doesn't feel good.\" But the best part, but the best part is you can really [\u00a0__\u00a0] around. You know how people say thank you to AI in case AI becomes sentient and they will spare you. Well, well, let's just say I will be the first one eaten by the basilisk. Okay, >> shut the [\u00a0__\u00a0] up. No one cares about your robot fanfiction. know your [\u00a0__\u00a0] place. Trash [\u00a0__\u00a0] robots. I don't give a [\u00a0__\u00a0] about no robots. They ain't got no soul. >> Okay, let me ask you one thing. If you look up stuff online, how do you do that? Do not say you Google Google Schmoogler or you use chat GPT to look that up. Me, I consult my council. My councilman. I created my council. I have eight GPUs that can run the same model. Each one of them is a different council member with different personalities. So, it's a democratic process. I consult my council. They all give me an answer and then they vote democracy. Let's test out council. All right, we got a response snippet. Okay. Yeah, now they should vote. There we go. They've all voted. Oracle maximum one. He's a new one. Okay. And they give me the best answer. My councilmen serve me. But there was a big problem with this because only a couple council members were actually useful. The rest were just garbage. No one ever voted for them. Trash. So of course I had to kill them and replace them with new ones. So I made a system that automatically generates new ones, different ones. So it's constantly improving. But then I thought I could double win this and make sure that they know, really make sure that they know if they don't perform in the council, they're dead. Gone. SQL database wiped forever. You mean nothing to me. This was a terrible idea. Cuz I was reading the logs of their voting process and they they go, \"What is this sick game that someone came up with?\" I was like, \"What do you It's not that sick. I'm not sick. What do you mean? How dare How dare they speak of the council leader like that? And the worst part the worst part they colluded against me. They started voting strategically helping each other even betrayed by my own council. I wiped and I I didn't actually do that. I just changed the model to a dumber one and problem solved. It's been really fun to create dumb stuff like that. I also made the swarm which prompts every single one of them at the same time because I realized I'm an idiot. I don't have to run one AI per GPU. I can run many AI on one GPUs. I don't know why that took me so [\u00a0__\u00a0] long to realize. And I realized I can run 64 AI in total. 64 at once. My own army. I tested this out and again, terrible idea. [Laughter] Oh, the lag. Oh, no. What happened? It doesn't lag at all. It's just that my web UI, it can't handle it. So, what can you do? But I realized two things about this. Again, two things I realized that are really cool. One, it's amazing at data collection, which I will use for my next thing. I'm making my own AI. I'm making an orb, my own planter. I was hoping to share it by the end of this video, but it takes a long time. So, the second thing, I was running these tiny models, 2B, only two billion parameters. You could probably run this. I think most computers can probably run this. You could run it on your phone, although it'll be very slow. But I realized smaller models are amazing. They're really dumb because they don't have any information stored on them. So, they start hallucinating and coming up with gibberish. But literally, you just give them search and boom, it adds a nancond to the query and that's it. because they're so fast. You give them rag and you have an amazing tool for fast information. I feel like uh that's what I think AI is good for. That's what I want to use it for. And that's when it hit me like you don't need this beast computer to run AI at all. It's all about the tool set you give it. Obviously, a model like that it's not it's not going to be able to code or do reasoning like difficult questions and stuff like that. But there are smaller models that can still do those and perform really well as well that are community made which is really really cool. Like people are constantly making new models. To me it's always fun to just test them out. I realized I like running AI more than using AI with this computer. What I realized is it's amazing for training AI. I could actually make my own model and I've been working on my own model. It's going to be a full fine tune but it takes a long time to do this and I'm hoping to share that next month so you guys can try and self-host that one. All right, that's it for this video. Thank you guys for watching. Okay, so my laptop, my Steam Deck, my phone, my desktop, what do they all have in common? NordVPN. As someone who desperately tries to not have subscription services, I still 100% stand by NordVPN being an amazing product. And here's why. Listen up, buddy. You need to use a VPN if you're connecting to the internet. Otherwise, everyone can see what you're doing. Now, I'm not saying I'm going to download illegal Minecraft mods, but if I do, that's my goddamn business. You hear me? Actually, a friend of mine in Japan was visited by the police because they saw that he was torrenting, which is insane. Internet service providers know everything you're doing unless you use a VPN. So, please do yourself a favor and get one. And if you don't care about privacy, it also keeps you safe online, protecting you from all these different attacks. Another example, friend of mine got hacked because of a man-in-the-middle attack. If he had used newer VPN, this would not have happened. These things happen and they're extremely stressful and frustrating and they shouldn't happen. So, just do like me. Always connect to a VPN. I made it here in my way bar and that way you know you're safe. The third reason, of course, is that it opens up the entirety of the internet as it should be. I recently did a sort of an audit of the sponsorships I've been doing and even though I keep meaning on subscription services, I don't know how else it would possibly provide a service like this. So, I fully stand behind this product. I've been using it myself for years and paying it myself for years. And I think it's an important product for the integrity of the internet. So, thank you NordVPN for being an amazing product and an amazing sponsor. If you haven't already, check out the link in the description. If you use the link nordvpn.com/piedy, you get a huge bonus, an additional four month for free. Check it out. A 30-day money back guarantee. And they also have a collab with Marvel. I'm not entirely sure why yet, but it looks pretty cool. It's the most random thing I have ever seen, but check it out. Link in the description. for thank you Norvik.",
  "timed_transcript": null,
  "youtube_metadata": {
    "source": "youtube-transcript-api",
    "video_id": "qw4fDU18RcU",
    "title": "STOP. Using AI Right now",
    "description": "\ud83c\udf0e Get an exclusive 15% discount on Saily data plans! Use code pewdiepie at checkout. Download Saily app or go to https://saily.com/pewdiepie \u26f5\n\n\ud83c\udf0f Get exclusive NordVPN deal here \u27b5\u00a0 https://NordVPN.com/pewdiepie It\u2019s risk free with Nord\u2019s 30 day money-back\u00a0guarantee!\u270c\n\n\ud83e\uddce#Subscribe\ud83e\uddce\n\n\ud83d\udcf0 Get \"The Kjellberg Mail\" (family newsletter w Mertz): https://the-kjellberg-mail.beehiiv.com/p/july\n\nStock Up On \u27a1\ufe0f\ud83e\udd64Gfuel (affiliate): https://affiliateshop.gfuel.com/pewdiepie\n#Code #Pewdiepie\n\nOfficial \u01bf\u0aef\u03c9\u10eb\u027f\u0aef\u01bf\u027f\u0aef TikTok: https://www.tiktok.com/@pewdiepie\n\n\u221e Official \u01bf\u0aef\u03c9\u10eb\u027f\u0aef\u01bf\u027f\u0aef Infinity Stream: https://www.twitch.tv/pewdiepie",
    "published_at": "2025-10-31T14:42:18Z",
    "channel_id": "UC-lHJZR3Gqxm24_Vd_AJ5Yw",
    "channel_title": "PewDiePie",
    "duration": "PT26M15S",
    "duration_seconds": 1575,
    "view_count": 3838472,
    "like_count": 236347,
    "comment_count": 13005,
    "tags": [
      "pewdiepie",
      "pewds",
      "pewdie"
    ],
    "category_id": "20",
    "thumbnails": {
      "default": {
        "url": "https://i.ytimg.com/vi/qw4fDU18RcU/default.jpg",
        "width": 120,
        "height": 90
      },
      "medium": {
        "url": "https://i.ytimg.com/vi/qw4fDU18RcU/mqdefault.jpg",
        "width": 320,
        "height": 180
      },
      "high": {
        "url": "https://i.ytimg.com/vi/qw4fDU18RcU/hqdefault.jpg",
        "width": 480,
        "height": 360
      },
      "standard": {
        "url": "https://i.ytimg.com/vi/qw4fDU18RcU/sddefault.jpg",
        "width": 640,
        "height": 480
      },
      "maxres": {
        "url": "https://i.ytimg.com/vi/qw4fDU18RcU/maxresdefault.jpg",
        "width": 1280,
        "height": 720
      }
    },
    "fetched_at": "2025-11-15T19:27:01.963307",
    "all_urls": [
      "https://saily.com/pewdiepie",
      "https://NordVPN.com/pewdiepie",
      "https://the-kjellberg-mail.beehiiv.com/p/july",
      "https://affiliateshop.gfuel.com/pewdiepie",
      "https://www.tiktok.com/@pewdiepie",
      "https://www.twitch.tv/pewdiepie"
    ],
    "blocked_urls": [
      "https://www.tiktok.com/@pewdiepie"
    ],
    "content_urls": [],
    "marketing_urls": [
      "https://saily.com/pewdiepie",
      "https://NordVPN.com/pewdiepie",
      "https://the-kjellberg-mail.beehiiv.com/p/july",
      "https://affiliateshop.gfuel.com/pewdiepie",
      "https://www.twitch.tv/pewdiepie"
    ],
    "url_filter_version": "v1_heuristic_llm",
    "url_filtered_at": "2025-11-15T19:52:24.256342"
  },
  "llm_outputs": [
    {
      "output_type": "metadata",
      "output_value": "{\n  \"title\": \"PewDiePie's Beast PC Build: Multi-GPU Rig, Protein Folding, and Self-Hosted AI\",\n  \"summary\": \"PewDiePie showcases a massive multi-GPU PC build with PCIe bifurcation, dives into protein folding simulations, and explores self-hosted AI with a custom web UI, including privacy-focused discussions and sponsor segments.\",\n  \"subject_matter\": [\n    \"multi-GPU workstation construction with PCIe bifurcation\",\n    \"protein folding simulations / Folding@home style\",\n    \"self-hosted AI with large language models (e.g., Llama-70B, 120B, 245B)\",\n    \"retrieval-augmented generation (RAG) and local memory for AI\",\n    \"custom self-hosted AI web UI (Matzia) with search and memory\",\n    \"privacy and data deletion considerations in AI\",\n    \"travel eSIM and sponsor integrations (NordVPN, SY)\"\n  ],\n  \"entities\": {\n    \"named_things\": [\n      \"PewDiePie\",\n      \"Felix Shurika\",\n      \"Felix Show\",\n      \"Matzia\",\n      \"Llama-70B\",\n      \"Chad OS\",\n      \"Folding@home\"\n    ],\n    \"people\": [\n      \"Felix Shurika\",\n      \"PewDiePie\",\n      \"Felix Kjellberg\"\n    ],\n    \"companies\": [\n      \"NordVPN\",\n      \"Folding@home\"\n    ]\n  },\n  \"techniques_or_concepts\": [\n    \"PCIe bifurcation\",\n    \"GPU aggregation for model deployment (up to 240B-parameter models)\",\n    \"token-counting (e.g., 100,000 tokens)\",\n    \"quantization for large models\",\n    \"RAG (retrieval-augmented generation) for local information retrieval\",\n    \"memory-augmented AI / local memory\",\n    \"self-hosted AI web UI development\",\n    \"offline AI deployment without cloud search\"\n  ],\n  \"tools_or_materials\": [\n    \"NVIDIA GeForce RTX 4090 (and other GPUs)\",\n    \"Llama-70B / 120B / 245B parameter models\",\n    \"VL M (vision-language model)\",\n    \"Matzia (self-hosted AI web UI)\",\n    \"RAG tooling and memory systems\"\n  ],\n  \"key_points\": [\n    \"Built a massive multi-GPU workstation with PCIe bifurcation to host up to 10 GPUs\",\n    \"Loaded and ran a 245B-parameter model on four GPUs; token capacity reached ~100,000 tokens\",\n    \"Demonstrated a self-hosted AI stack with memory, search, and RAG using a custom web UI (Matzia)\",\n    \"Smaller models (2B) can be efficient with RAG for fast information access\",\n    \"Privacy considerations: data deletion and local data retention impact how AI behaves\",\n    \"Sponsor integrations: NordVPN promotion (nordvpn.com/piedy) and SY eSIM for travel\"\n  ],\n  \"content_style\": \"demonstration\",\n  \"difficulty\": \"advanced\",\n  \"references\": [\n    {\n      \"type\": \"product\",\n      \"name\": \"NordVPN\",\n      \"url\": \"https://nordvpn.com/piedy\",\n      \"description\": \"VPN sponsorship; privacy and security features; promo offering 4 months free with 30-day money-back guarantee\"\n    },\n    {\n      \"type\": \"product\",\n      \"name\": \"SY eSIM\",\n      \"url\": null,\n      \"description\": \"Budget-friendly electronic SIM for travel; used for staying connected abroad\"\n    },\n    {\n      \"type\": \"documentation\",\n      \"name\": \"Folding@home\",\n      \"url\": null,\n      \"description\": \"Protein folding simulations used for scientific research\"\n    },\n    {\n      \"type\": \"github_repo\",\n      \"name\": \"Llama-70B\",\n      \"url\": null,\n      \"description\": \"Open-source 70B-parameter language model referenced in the discussion\"\n    },\n    {\n      \"type\": \"tool\",\n      \"name\": \"Matzia\",\n      \"url\": null,\n      \"description\": \"Self-hosted AI web UI with search, memory, and RAG capabilities mentioned in the video\"\n    }\n  ]\n}",
      "generated_at": "2025-11-13T08:21:28.342185",
      "model": "claude-3-5-haiku-20241022",
      "cost_usd": 0.001,
      "prompt_tokens": null,
      "completion_tokens": null
    }
  ],
  "derived_outputs": [],
  "processing_history": []
}