{
  "video_id": "v6tZ1Wcg-YU",
  "url": "https://www.youtube.com/watch?v=v6tZ1Wcg-YU",
  "fetched_at": "2025-11-09T23:50:43.542698",
  "source": "youtube-transcript-api",
  "import_metadata": {
    "source_type": "bulk_channel",
    "imported_at": "2025-11-09T23:50:43.542698",
    "import_method": "cli",
    "channel_context": {
      "channel_id": null,
      "channel_name": null,
      "is_bulk_import": true
    },
    "recommendation_weight": 0.5
  },
  "raw_transcript": "You know, Ilia Sutskiver said data is the new oil, which is, I suppose, not a new thing to say, but it's Ilia, and he's one of the leading lights of the AI generation. And when he said it at Nurips in November 2024, we all paid attention. There have been two major trend lines since then that make me think that Ilia needs to update his priors. I know, who am I to say that? I'm nobody to say that. So, let me just finish my thing. Uh number one, data is getting locked off actively. And this is something that's actually in favor of Ilia's contention. Right? So Ilia's contention is that we're running out of data to train on because there's only so much data in the world to train on. What if we're running out faster than he thought because people are actively locking off sources of data? We see that on a few places. Uh, one, if you've been on this channel, OpenAI bought Windinsurf. Enthropic cut off model access to Windsurf for their clawed models because you don't want to let those guys get the models, right? Then the model output tokens would go to their rival OpenAI and that would be a problem. It's a data lockoff. And this is for future data streams. This is for data that users generate in the tool. what I would call usergenerated artificial data because it's artificial because it's coming from a model but it's userenerated because you're prompting for it. I think it's one of the biggest sources of renewable data that we have. Chat GPT generates a ton of user generated artificial data. Uh it's one of their greatest sources of data. I would hypothesize. Uh and anthropic did not want that valuable code data to go to OpenAI. Okay. Second development in that direction, Salesforce has reportedly cut the rapidly growing uh company Glean off from getting access to Slack messages. And why does that matter? Glean specializes in dealing with a single pane of glass that executives can see what's happening in the whole business. They need Slack to do it. And so Salesforce is cutting glean off at the knees because Salesforce views Slack data as highly valuable in the age of AI. And I would agree. I think it is. But Salesforce is making moves they didn't make last year because they understand better at the executive level that they need to ring fence that data in order to prevent people from getting a hold of it. And again, this is not necessarily usergenerated artificial tokens in this case. This is just userenerated data. We're typing in Slack all day. Well, now Gleam can't get a hold of it. I would expect those restrictions to continue to tighten. Third one is uh on the legal side. I talked about the New York Times suing OpenAI and kind of some of the problems with that. Disney suing Midjourney is sort of the next generation lawsuit here. They're basically saying that MidJourney uh allow uh allows users to create proprietary Disney characters. And without getting into the merits of the case, I think the story from the data side is essentially Disney is trying to lock off huge chunks of the data landscape to trainers and models. Similar to what the New York Times is doing, chunks of the data landscape. Now, individually, these maybe huge chunks isn't fair. They're huge in terms of you know nominal value gigabytes and so on terabytes pabyte maybe but they're not huge on the scale of like zetabytes not huge on the scale of the internet so I think if you remove them the models would go on much as before so three different ways in which we're cutting off access to data making data uh effectively less common less available more of a resource that Ilia would say is not coming back and that we have to be careful with. Right? So this is in favor of Ilia's contention and in fact suggests that we may be accelerating the scarcity of data. But two is a little bit different. Um theme two is this idea that we are taking data and we are very rapidly using machines to iterate on machine generated data. Now there was a very famous study done too long ago to matter which means 2023 in AI terms that suggest that synthetic data generated by AI can't be reliably used by AI. That's not true anymore. Uh you have reports coming out of multiple major model makers that synthetic tokens are useful in the process of training. And now we've gone the next step. There are reports that there are automated iterative improvements at multiple major model makers driven by autonomous AI. And so this that I've seen leaks from both Anthropic and from OpenAI on the internet both suggest independently that they are working through the concept of AIdriven reinforcement learning. So instead of humans saying is this a good thing or not and driving reinforcement learning which trains the model what responses to prefer or not they're getting better responses out of the model by letting AI do the reinforcement learning on AI. AI taking over the training of AI, which if you're wondering is one of the big steps toward a generalized intelligence explosion because if AI can do it, there's really no barrier except power, right? You just turn on more power and AI can do more of it. And so in that world, does data still matter if you can use AI to generate synthetic tokens and then use AI to reinforcement learn your way through? And the answer may be you don't really need the data, but you do have alignment questions, and that's a separate conversation. But it's one of those things where I've been watching the longer term trend line since Nurips's uh which is the conference IA spoke at where he talked about the data piece and I've been saying well what how's the data story evolving in 2025 and I think the story is basically executives are waking up and shutting data off wherever they can and at the same time model makers are innovating and basically finding ways for it not to matter. They're finding ways for AI to drive reinforcement learning on synthetic tokens. So it's like well if you cut off the data it doesn't matter. You tell me where do you think the data story is going in the rest of 2025.",
  "timed_transcript": null,
  "youtube_metadata": {
    "source": "youtube-transcript-api",
    "video_id": "v6tZ1Wcg-YU",
    "title": "The Data Scarcity Myth: Data is Disappearing, but AI is Learning to Grow Itself",
    "description": "More here: https://open.substack.com/pub/natesnewsletter/p/ais-synthetic-summer-the-2025-mid?r=1z4sm5&utm_campaign=post&utm_medium=web&showWelcomeOnShare=true\n\nMy site: https://natebjones.com/\nMy links: https://linktr.ee/natebjones\nMy substack: https://natesnewsletter.substack.com/\n\nTakeaways\n 1. Data Ring-Fencing Accelerates: Major players are actively walling off live data streams\u2014Slack logs, publisher archives, and copyrighted IP\u2014turning once-open corpora into guarded assets.\n 2. Slack-Glean Block Shows Platform Guarding: Salesforce\u2019s move to cut Glean from Slack underscores a new corporate instinct to keep high-value internal conversations out of rival AI pipelines.\n 3. Legal Suits Narrow Training Pools: Disney-MidJourney and New York Times-OpenAI lawsuits aim to restrict use of branded or premium content, signaling more courtroom gatekeeping of training data.\n 4. User-Generated Artificial Data Matters: Model outputs created inside products such as ChatGPT constitute a rich \u201crenewable\u201d data source\u2014firms now view these prompt-driven tokens as proprietary gold.\n 5. Synthetic Tokens Become Training Fuel: 2025 leaks from OpenAI and Anthropic confirm that AI-generated text can now improve future models, overturning the 2023 belief that synthetic data was toxic.\n 6. AI-Driven Reinforcement Loops Emerge: Labs are letting autonomous agents run reinforcement learning, replacing costly human labelers and pushing toward self-improving systems limited mainly by compute.\n 7. Scarcity Shifts from Data to Power: As synthetic data and self-training take hold, raw compute\u2014not open corpora\u2014becomes the primary bottleneck for frontier-model progress.\n\nQuotes\n\u201cWe\u2019re watching executives slam data doors faster than model makers can knock.\u201d\n\u201cIf AI handles the reinforcement, the only limit left is power\u2014not data.\u201d\n\u201cThe 2025 battle isn\u2019t about bigger models; it\u2019s about who owns the feedback loop.\u201d\n\nSummary\nSince Ilya Sutskever framed data as the new oil, two opposing forces have emerged. Executives are ring-fencing live data streams\u2014Slack, publisher archives, copyrighted IP\u2014forcing would-be trainers to scramble. Simultaneously, model labs are proving that synthetic tokens and AI-driven reinforcement loops can replace much of that lost fuel. Anthropic\u2019s and OpenAI\u2019s internal experiments show autonomous RL improving models without human labelers. If AI can grade its own work, scale is limited chiefly by compute. The result: data itself becomes politicized property while leading labs race to self-generate learning material, testing both quality and reliability in a rapidly global feedback arms race.\n\nKeywords\nIlya Sutskovor, data lock-off, synthetic data, user-generated artificial data, reinforcement learning, AI training, Slack data, Salesforce, Glean, Disney lawsuit, MidJourney, New York Times vs OpenAI, data scarcity, 2025 AI trends, compute scaling, feedback loops",
    "published_at": "2025-06-13T13:01:40Z",
    "channel_id": "UC0C-17n9iuUQPylguM1d-lQ",
    "channel_title": "AI News & Strategy Daily | Nate B Jones",
    "duration": "PT6M58S",
    "duration_seconds": 418,
    "view_count": 5264,
    "like_count": 248,
    "comment_count": 47,
    "tags": [],
    "category_id": "22",
    "thumbnails": {
      "default": {
        "url": "https://i.ytimg.com/vi/v6tZ1Wcg-YU/default.jpg",
        "width": 120,
        "height": 90
      },
      "medium": {
        "url": "https://i.ytimg.com/vi/v6tZ1Wcg-YU/mqdefault.jpg",
        "width": 320,
        "height": 180
      },
      "high": {
        "url": "https://i.ytimg.com/vi/v6tZ1Wcg-YU/hqdefault.jpg",
        "width": 480,
        "height": 360
      },
      "standard": {
        "url": "https://i.ytimg.com/vi/v6tZ1Wcg-YU/sddefault.jpg",
        "width": 640,
        "height": 480
      },
      "maxres": {
        "url": "https://i.ytimg.com/vi/v6tZ1Wcg-YU/maxresdefault.jpg",
        "width": 1280,
        "height": 720
      }
    },
    "fetched_at": "2025-11-15T19:27:31.151603",
    "all_urls": [
      "https://open.substack.com/pub/natesnewsletter/p/ais-synthetic-summer-the-2025-mid?r=1z4sm5&utm_campaign=post&utm_medium=web&showWelcomeOnShare=true",
      "https://natebjones.com/",
      "https://linktr.ee/natebjones",
      "https://natesnewsletter.substack.com/"
    ],
    "blocked_urls": [
      "https://linktr.ee/natebjones"
    ],
    "content_urls": [
      "https://open.substack.com/pub/natesnewsletter/p/ais-synthetic-summer-the-2025-mid?r=1z4sm5&utm_campaign=post&utm_medium=web&showWelcomeOnShare=true",
      "https://natesnewsletter.substack.com/"
    ],
    "marketing_urls": [
      "https://natebjones.com/"
    ],
    "url_filter_version": "v1_heuristic_llm",
    "url_filtered_at": "2025-11-15T19:52:26.213312"
  },
  "llm_outputs": [
    {
      "output_type": "tags",
      "output_value": "{\n  \"video_title\": \"data scarcity and ai-driven training trends in 2025\",\n  \"tags\": [\"data-scarcity\", \"synthetic-data\", \"ai-training\", \"reinforcement-learning\", \"data-access-restrictions\"],\n  \"summary\": \"Discussion on rising data scarcity, how data is being locked off by major players, and the shift toward AI-driven training with synthetic data and automated reinforcement learning.\"\n}",
      "generated_at": "2025-11-09T23:50:56.533462",
      "model": "claude-3-5-haiku-20241022",
      "cost_usd": 0.001,
      "prompt_tokens": null,
      "completion_tokens": null
    }
  ],
  "derived_outputs": [],
  "processing_history": []
}