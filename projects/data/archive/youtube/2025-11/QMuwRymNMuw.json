{
  "video_id": "QMuwRymNMuw",
  "url": "https://www.youtube.com/watch?v=QMuwRymNMuw",
  "fetched_at": "2025-11-10T00:35:01.941441",
  "source": "youtube-transcript-api",
  "import_metadata": {
    "source_type": "bulk_channel",
    "imported_at": "2025-11-10T00:35:01.941441",
    "import_method": "cli",
    "channel_context": {
      "channel_id": null,
      "channel_name": null,
      "is_bulk_import": true
    },
    "recommendation_weight": 0.5
  },
  "raw_transcript": "what if I told you that there was a four class model out there that was 10 times cheaper to build maintain and execute on so Chad gp4 set the bar for models in 2024 it's since been surpassed by inference time compute models like 01 01 pro3 but it's still really really good at a lot of different things it's good at English it's good at coding it's good at math Etc well there's now a new model instead of costing the 70 or100 million that chat GPT cost to train similar cost for Claude this model only cost $5 million maybe 5 a half that is not that much A lot of startups have $5 million it's a lot for an individual but a lot of startups have $5 million and it's really amazing to see a world where we could actually Envision individual startups being able to build their own models and this is something that the makers of this model have chosen to open source so it's something anybody can look at and say how could I make it even better or how could I do it myself and they've done a number of really interesting things throughout the model build process that they are revealing to the world and I just want to highlight a couple I'll share the paper in the in the description here this is deep seek V3 it's very cool so the training data was something they took a lot of care with they did not do sort of the suck up the whole internet vibe that chat GPT did they actually had a very specific training Corpus of very high quality tokens that they trained against and they really really reviewed it to make sure it was good at English good at Chinese good at math and good at coding and then they reinforced that carefully with human responses to ensure it was really really accurate and that gave them a lot of confidence during query time so when you type in a query it gave them confidence to actually predict more tokens ahead and be more efficient in their use of space so even though this is a very large model it's like 617 billion tokens right it's a very large model uh large for a four class model like it's it's it's not something that you would expect to be this efficient is the way I'll put it but they have figured out that you can use just a sliver of that total model space in the response and it's about picking the right sliver and so where other models like metas Llama Or Claude or Chad GPT use the whole model space this model only uses 37 billion uh parameters out of the 617 billion parameter model for any given response and so it's about picking the WR 37 billion which sounds like a lot of parameters Until you realize it's such a tiny percentage of the total in the model and they're actually making very efficient use of comput they're also able to predict more than one token ahead because they're so confident in their training data and so instead of predicting only one token head they're predicting two and that's a really cool Innovation I expect to see other folks go after that as well now they did some other cool things during the training phase they had something called dual pipe which I've tried to explain a couple of times on video It's rather complicated it basically amounts to being able to regurgitate and learn at the same time and they had a special network setup to do that they outlined that in the paper I definitely recommend diving in for the details there but from a from a strategic perspective if we step back what this really means is that models have gone from being something that are in the hundred million doll class only a few startups could ever afford to anybody can build this if they have startup level seed uh investment that is a mass massive massive shift it is going to make more and more four class models available and it's going to be yet another driver in this overall strategic theme of four class intelligence becoming essentially free they've open sourced this model anybody can use it right now and anybody can replicate it right now so if you think about it we now have a world where four class models are becoming free and The Cutting Edge is an inference time compute and these models don't really use the multi-threaded uh multi token prediction that inference time compute has where you type in a query and it runs but lots and lots of different next token prediction threads and finds the best one now that may get open source next year right like the pace we're going at we may well see a model like that get open source next year but for now that is the model and that is The Edge that chat GPT has in the space nobody else really has that kind of inference time compute yet lots of people are working on it and the four class models like Claude Sonet 3.5 5 or 3.6 like chat GPT 40 those are rapidly getting replicated cost is driving to zero it's a it's a massive achievement like and I will grant you it is easier to innovate than it is to replicate so getting to the first chat gpg 4 May well have cost $100 million no matter how you did it because it was the first time but replicating it turns out to be very very efficient and very very affordable relatively speaking and that has huge implications because it means that intelligence is going to be more and more and more free for a lot of different applications that matter in business so we will see but right now a $5 million model is beating 40 and Son 3.5 at a lot of the things that people really use these models for like English like math like coding Etc so there you have it deep seek V3 new four class model Champion cheers",
  "timed_transcript": null,
  "youtube_metadata": {
    "source": "youtube-transcript-api",
    "video_id": "QMuwRymNMuw",
    "title": "This model is better than ChatGPT and 10x cheaper",
    "description": "About me: https://natebjones.com/\nMy links: https://linktr.ee/natebjones\nModel: https://www.deepseek.com/\nPaper: https://github.com/deepseek-ai/DeepSeek-V3/blob/main/DeepSeek_V3.pdf\n\nTakeaways:\n 1. Affordable AI Training Costs: DeepSeek V3 was built with just $5.5M in training costs, proving that world-class AI can now be developed at a fraction of the cost compared to GPT-4\u2019s estimated $100M.\n 2. Selective Parameter Usage: DeepSeek activates only 37B parameters of its 617B total for any given task, making it 10x more efficient than models like ChatGPT and Claude.\n 3. DualPipe Efficiency: DualPipe allows the model to learn and work simultaneously, reducing computational bottlenecks and enabling faster, cost-effective training.\n 4. Multi-Token Prediction (MTP): The model predicts two words ahead instead of one, improving response speed and accuracy on benchmarks like math and coding.\n 5. High-Quality Training Data: Instead of scraping the internet, DeepSeek curated high-quality data focused on English, Chinese, math, and coding, ensuring superior performance across diverse tasks.\n 6. Open Source Accessibility: By open-sourcing DeepSeek V3, the creators have democratized AI development, enabling startups and developers to build or customize their own models.\n 7. Strategic Implications: This breakthrough signals a shift toward making advanced AI accessible and affordable, driving competition and innovation beyond tech giants.\n\nQuotes:\n \u2022 \u201cDeepSeek didn\u2019t just build an AI model; they rewrote the economics of AI development.\u201d\n \u2022 \u201cPredicting two words ahead instead of one may sound simple, but it\u2019s a game-changer for efficiency and speed.\u201d\n \u2022 \u201cThis isn\u2019t just cheaper AI\u2014it\u2019s smarter AI that anyone can use or build on.\u201d\n\nSummary:\nDeepSeek V3 sets a new benchmark for AI with groundbreaking efficiency. It was trained for just $5.5M, significantly less than GPT-4, and uses only 37B of its 617B parameters per task, making it incredibly resource-efficient. With innovations like DualPipe for simultaneous learning and multi-token prediction, it outperforms competitors in coding, math, and language tasks. DeepSeek\u2019s use of high-quality, curated data and open-sourcing of the model makes this breakthrough accessible to startups and individuals, democratizing the future of AI development. This achievement marks a shift in AI\u2019s trajectory, making cutting-edge technology more affordable and inclusive.\n\nKeywords:\nDeepSeek, GPT-4, AI efficiency, affordable AI, $5.5M AI, parameter optimization, DualPipe, multi-token prediction, MTP, curated training data, open source AI, AI accessibility, startup AI, Claude 3.5, ChatGPT, math performance, coding performance, LLM, AI democratization, innovation, AI economics",
    "published_at": "2024-12-27T20:00:31Z",
    "channel_id": "UC0C-17n9iuUQPylguM1d-lQ",
    "channel_title": "AI News & Strategy Daily | Nate B Jones",
    "duration": "PT5M25S",
    "duration_seconds": 325,
    "view_count": 6085,
    "like_count": 293,
    "comment_count": 39,
    "tags": [],
    "category_id": "22",
    "thumbnails": {
      "default": {
        "url": "https://i.ytimg.com/vi/QMuwRymNMuw/default.jpg",
        "width": 120,
        "height": 90
      },
      "medium": {
        "url": "https://i.ytimg.com/vi/QMuwRymNMuw/mqdefault.jpg",
        "width": 320,
        "height": 180
      },
      "high": {
        "url": "https://i.ytimg.com/vi/QMuwRymNMuw/hqdefault.jpg",
        "width": 480,
        "height": 360
      },
      "standard": {
        "url": "https://i.ytimg.com/vi/QMuwRymNMuw/sddefault.jpg",
        "width": 640,
        "height": 480
      },
      "maxres": {
        "url": "https://i.ytimg.com/vi/QMuwRymNMuw/maxresdefault.jpg",
        "width": 1280,
        "height": 720
      }
    },
    "fetched_at": "2025-11-15T19:26:57.896599",
    "all_urls": [
      "https://natebjones.com/",
      "https://linktr.ee/natebjones",
      "https://www.deepseek.com/",
      "https://github.com/deepseek-ai/DeepSeek-V3/blob/main/DeepSeek_V3.pdf"
    ],
    "blocked_urls": [
      "https://linktr.ee/natebjones"
    ],
    "content_urls": [
      "https://github.com/deepseek-ai/DeepSeek-V3/blob/main/DeepSeek_V3.pdf"
    ],
    "marketing_urls": [
      "https://natebjones.com/",
      "https://www.deepseek.com/"
    ],
    "url_filter_version": "v1_heuristic_llm",
    "url_filtered_at": "2025-11-15T19:52:24.007932"
  },
  "llm_outputs": [
    {
      "output_type": "tags",
      "output_value": "{\n  \"video_title\": \"DeepSeek V3: Open-Source Four-Class AI Model and Its Training Innovations\",\n  \"tags\": [\"open-source-ai\", \"four-class-model\", \"deepseek-v3\", \"ai-training-cost\"],\n  \"summary\": \"Explains the DeepSeek V3 four-class AI model, its affordable training cost, efficient use of parameters, and implications for accessible, open-source AI.\"\n}",
      "generated_at": "2025-11-10T00:35:12.953634",
      "model": "claude-3-5-haiku-20241022",
      "cost_usd": 0.001,
      "prompt_tokens": null,
      "completion_tokens": null
    }
  ],
  "derived_outputs": [],
  "processing_history": []
}