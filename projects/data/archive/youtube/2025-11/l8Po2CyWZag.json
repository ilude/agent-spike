{
  "video_id": "l8Po2CyWZag",
  "url": "https://www.youtube.com/watch?v=l8Po2CyWZag",
  "fetched_at": "2025-11-09T23:49:34.677041",
  "source": "youtube-transcript-api",
  "import_metadata": {
    "source_type": "bulk_channel",
    "imported_at": "2025-11-09T23:49:34.677041",
    "import_method": "cli",
    "channel_context": {
      "channel_id": null,
      "channel_name": null,
      "is_bulk_import": true
    },
    "recommendation_weight": 0.5
  },
  "raw_transcript": "Code has gone through more evolution in the last 50 or 60 years than natural language has gone through since it was invented 200,000 years ago and since writing was invented a few tens of thousands of years ago maybe less. The point is code is evolving fast because code was designed to evolve with developing uh and more powerful computer systems and natural language has only been bolted onto computers. It's not really a computative technology. I want you to think about it. Code started out as you compose it, you stick it in, you hope it runs. We are so far past that and we have seen step change improvements as we have leveraged better code practices with more complex compute. So now we have DevOps as a discipline. That wasn't a thing when I was coming up. It was only a thing after the 2010s. We have like the idea of having a testing environment, the idea of having a staging environment, the idea of having CI/CD pipelines, the idea of GitHub. These are all innovations that combine the power of compute with code. And they're possible because code was designed first and foremost to be a language that worked well with computers. That's why we have it. It's a simplified language. It worked well with traditional computers. Fast forward now it's 2022. Machines understand natural language. They understand the language we have been speaking for hundreds of thousands of years. They understand the language we have been writing. We for the first time have machines that can master the semantic technical complexity of language. Language is much more complex. Natural language much more complex than computer code. It can express a much wider range of meaning. The complexity it can handle is much greater. Great literature in particular is extremely dense, highly complex, etc. Machines can speak and understand that. Machines have been trained on that. And yes, I'm the first person to say machines are not yet writing great literature. Uh I'm not trying to make that claim here. The point is this. Our tools for writing on computers have been bolted on for decades. They've been bolted on and we've just been tapping and writing out really the same fundamental technology that we've had since the beginning. And I know that one of the hot new things in 2025 is voice. But guess what? It can't be that hot. It's actually going back to before we invented writing to when we were in oral culture. It's just voice again, only now we have computers in the mix. It's not actually a new innovation. It's just going back to the way our brains were originally wired. And it's often easier to engage that part of the brain because writing is a learned technology and human brains haven't evolved to make it truly native yet. So far so good. But you know what is going to happen that is truly compute align that is a computen native innovation on writing. We are going to have AI native tooling for writing. I don't mean you have a chat bar and then suddenly everything appears. I'm going to give you a little hint of it and I think we can infer a lot about how white collar work is going to go based on this by the way because if you think about it how much of our work right now is document creation if you're not coding which as we've seen is compute native it's seen the fastest development before AI frankly given cursor given windsurf and others I would argue it's seen the fastest development since AI the rest of us we're making documents and you know what I know there are enterprises that have document pipelines that use AI. I'm aware of them. I've advised on a few of them, but those are all almost without exception tightly complexity constrained because they have to be given the scale. Whereas traditional knowledge work is actually very complexity expansive. It's it's closer to the range of natural language. You have to do a lot of different things with documents. It's part of what makes white collar work actually quite difficult to understand and automate. It's really complicated. And what I'm saying here is not like a direct path to automation A to B. What I'm saying is that as machines understand our language, we can finally develop software that leverages compute to give us more options. And this is where I come back around and say again, it's probably not the chatbot, even though the chatbot is what we're using right now. It is probably going to be something that puts uh optionality and leverage first and foremost. So, for example, look at the way you can get multiple variants easily with AI. There's no reason that has to be a point and a click or a type away. It can be native and obvious. There are a few tools that already are playing with this idea where you just have multiple variants of everything you write. Another one, why don't we have the concept of production code for writing documents? I know we have draft and I know we have final but we don't really think of our software for documents as being something that we could evolve with AI so that we have like the right model for drafting we have the right verification step and staging for checking our facts and claims and we treat it like code in the sense that we check it for clarity we check it for coherence then we finally deploy it to production is that too technical a way of thinking about it I don't think so because I think you can take that same princip principle and then at the end if you want to dress it up and make it a fancy report that just becomes a separate step at the presentation layer. The core of the context, the core of the text is still there. Imagine how much easier it is if you can deploy text across multiple channels at once. That way, it's like being able to deploy code to multiple boxes. You would be able to say, \"Okay, so we're going to tweak this core message. We're going to send it in um a multivariant stream, right? We're going to have cohort one be the executive team, cohort two be the marketers, cohort 3 be customer success, and you're sending the same update, but you're tuning it to what they need to hear and focus on. That's all stuff that was not possible before because AI did not give us the chance to understand natural language until the popularization of large language models. We had AI before then, but true large language models were the breakthrough we needed to grasp the depth and complexity of text. And that enables us for the very first time to have compute platforms that actually evolve the way we think and write and take us beyond what we've been doing for tens of thousands of years. I'm very excited about it. I can't tell you how exactly it's going to look, but I will say I am already seeing professional AI workers do this manually. For example, I am going to be moving my document flow from chat GPT to drafting with 03 because I think 03 is a good conceptual thinker. Maybe sometimes if it's a hard problem, I'll go to 03 Pro and then move from there into Opus 4 to understand and structure the problem a little bit. You see how I'm thinking about it? moving from the dev environment now I'm starting to move it into almost a pull request merge scenario where I have to think about the structure of what I'm writing and whether it is congruent with other things that I've written and other things I'm focused on then moving it to what I would call testing where you're going to perplexity with that document and you're testing whether the claims are true and then moving for polishing to sonnet 4 also a claude model because sonnet 4 is an exceptional writer and it's able to polish that text a little bit more. I would call that, you know, staging, getting ready for production, whatever you want to say. The point is, I am essentially mimicking that dev pipeline. And I'm not the only one. Lots of people are doing this, but I think we've been doing it individually on our own. And we talk about it as if it's finding the best model for this and this and it gives us a headache because it feels like we have to constantly be picking better models. I think it's more stable and helpful to think about it as we are not equipped yet with tools that make writing native for AI. We could be eventually in the meantime. This is our best way to manually simulate it. And if we understand the jobs as mapping sort of loosely to the leverage that code has been able to get through more compute I think we're going to get farther because to be honest it's actually not that much of a stretch to say most knowledge work goes through development it goes through testing it goes through a merge process we call that peer review and it eventually gets to production. It's kind of how it works. If we can figure out how to do that with computer programs that are small, with smaller scale compute, we're going to be able to figure out how to make that easier for ourselves, with LLMs, with larger scale compute, and with all the power of natural language that makes knowledge work so interesting. So there you go. That is the thing that has been keeping me awake at night. That is the thing I cannot stop thinking about. I am so excited because I feel like we are standing on the edge of a different way of writing for the first time in a very long time. If you're out there building on that, if you're out there working on that, I know a few founders who are. I'm excited for you guys and cheering for you guys. In the meantime, I'm going to keep documenting how I build, how I learn, how I think, and uh yeah, good luck out there, guys. Cheers.",
  "timed_transcript": null,
  "youtube_metadata": {
    "source": "youtube-transcript-api",
    "video_id": "l8Po2CyWZag",
    "title": "Code Evolved More in 60 Years than Writing did in 5,000\u2014Now AI is About to Rewrite Writing",
    "description": "My site: https://natebjones.com/\nMy links: https://linktr.ee/natebjones\nMy substack: https://natesnewsletter.substack.com/\n\nTakeaways\n 1. Code vs. Language Pace: Code rocketed forward because it was designed for computers; natural language is only now becoming compute-native as LLMs learn to understand it.\n 2. DevOps Analogy for Writing: Future writing will adopt DevOps-style pipelines\u2014draft, test, stage, deploy\u2014powered by specialized AI models at each step.\n 3. AI-Native Document Tools: Chatbots are transitional; the breakthrough will be tools that make variant generation, fact verification, and multi-channel deployment effortless and built-in.\n 4. Manual Pipelines Today: Professional AI users already chain models (O3 \u2192 Opus 4 \u2192 Perplexity \u2192 Claude Sonnet) to mimic that pipeline, proving the concept works.\n 5. Knowledge-Work Leverage: Because most white-collar work is document creation, AI-native pipelines will unlock the same 200\u00d7 productivity gains code saw with CI/CD.\n 6. Voice Isn\u2019t the Innovation: Voice interfaces simply revive pre-literate habits; true novelty lies in compute-aligned writing workflows that harness language complexity.\n\nQuotes\n\u201cI\u2019m standing on the edge of a different way of writing\u2014one that treats text like deployable code.\u201d\n\u201cNatural language has been bolted onto computers for decades; LLMs finally make it a first-class, compute-native medium.\u201d\n\u201cChatbots are a waypoint; the real leap is an AI-native pipeline where drafting, verification, and deployment happen as smoothly as a CI/CD run.\u201d\n\nSummary\nI argue that code\u2019s explosive progress came from being designed for computers, while natural language stalled because it wasn\u2019t. Large language models change that. For the first time, machines grasp the semantic complexity of human text, letting us build AI-native tooling that parallels DevOps. I already chain models\u2014O3 for ideas, Opus 4 for structure, Perplexity for fact tests, Sonnet 4 for polish\u2014mirroring draft, test, stage, deploy. Future platforms will automate this, offering variant generation, claim verification, and channel-specific delivery as defaults. When writing becomes compute-native, knowledge work will gain the same exponential leverage code enjoyed with CI/CD.\n\nKeywords\nnatural language, compute-native, DevOps, CI/CD, AI-native writing, document pipeline, large language models, model chaining, knowledge work, variant generation, fact verification, O3, Opus 4, Perplexity, Claude Sonnet",
    "published_at": "2025-06-18T13:01:31Z",
    "channel_id": "UC0C-17n9iuUQPylguM1d-lQ",
    "channel_title": "AI News & Strategy Daily | Nate B Jones",
    "duration": "PT10M28S",
    "duration_seconds": 628,
    "view_count": 6735,
    "like_count": 416,
    "comment_count": 52,
    "tags": [],
    "category_id": "22",
    "thumbnails": {
      "default": {
        "url": "https://i.ytimg.com/vi/l8Po2CyWZag/default.jpg",
        "width": 120,
        "height": 90
      },
      "medium": {
        "url": "https://i.ytimg.com/vi/l8Po2CyWZag/mqdefault.jpg",
        "width": 320,
        "height": 180
      },
      "high": {
        "url": "https://i.ytimg.com/vi/l8Po2CyWZag/hqdefault.jpg",
        "width": 480,
        "height": 360
      },
      "standard": {
        "url": "https://i.ytimg.com/vi/l8Po2CyWZag/sddefault.jpg",
        "width": 640,
        "height": 480
      },
      "maxres": {
        "url": "https://i.ytimg.com/vi/l8Po2CyWZag/maxresdefault.jpg",
        "width": 1280,
        "height": 720
      }
    },
    "fetched_at": "2025-11-15T19:26:13.860089",
    "all_urls": [
      "https://natebjones.com/",
      "https://linktr.ee/natebjones",
      "https://natesnewsletter.substack.com/"
    ],
    "blocked_urls": [
      "https://linktr.ee/natebjones"
    ],
    "content_urls": [
      "https://natesnewsletter.substack.com/"
    ],
    "marketing_urls": [
      "https://natebjones.com/"
    ],
    "url_filter_version": "v1_heuristic_llm",
    "url_filtered_at": "2025-11-15T19:52:21.073940"
  },
  "llm_outputs": [
    {
      "output_type": "tags",
      "output_value": "{\n  \"video_title\": \"ai-native-writing and the future of knowledge-work\",\n  \"tags\": [\"ai-native-writing\", \"document-automation\", \"knowledge-work-automation\", \"large-language-models\"],\n  \"summary\": \"Explores how AI-native tooling and large language models are transforming writing, documents, and knowledge work from code-like pipelines to production-like document workflows.\"\n}",
      "generated_at": "2025-11-09T23:49:49.036280",
      "model": "claude-3-5-haiku-20241022",
      "cost_usd": 0.001,
      "prompt_tokens": null,
      "completion_tokens": null
    }
  ],
  "derived_outputs": [],
  "processing_history": []
}